{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import math\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_parse_BCJ(path, damage_model = None, damage_vectorizer = None):\n",
    "    '''Given file path (text file) of negligence cases, finds static \n",
    "    information within the case (information that can be pattern matched)\n",
    "    Expects a B.C.J. case format (British Columbia Judgments)\n",
    "    \n",
    "    The following fields are currently implemented:\n",
    "    - Case Title\n",
    "    - Judge Name\n",
    "    - Registry\n",
    "    - Year\n",
    "    - Decision Length (in paragraphs)\n",
    "    - Damages\n",
    "    - Multiple Defendants\n",
    "    - Plaintiff Wins\n",
    "    \n",
    "    Arguments: \n",
    "    doc (String): The case in text format following the form used in the DOCX to TXT notebook\n",
    "    [Optional] damage_model (sklearn model) - Used for damage classification. If not supplied uses rule based\n",
    "    [Optional] damage_vectorizer (DictVectorizer) Used for damage classification. If not supplied uses rule based\n",
    "    \n",
    "    Returns: case_parsed_data (list) of case_dict (Dictionary): List of Dictionaries with rule based parsable fields filled in\n",
    "    '''\n",
    "    with open(path, encoding='utf-8') as document:\n",
    "        document_data = document.read()\n",
    "        \n",
    "    document_data = document_data.split('End of Document\\n') # Always split on 'End of Document\\n'\n",
    "    case_parsed_data = []\n",
    "    for i in range(len(document_data)):\n",
    "        case_dict = dict() \n",
    "        case = document_data[i]\n",
    "        case = case.strip() # Make sure to strip!\n",
    "        if len(case) == 0: # Skip empty lines\n",
    "            continue\n",
    "        \n",
    "        lines = case.split('\\n')\n",
    "        if len(lines) < 2:\n",
    "            print(case)\n",
    "        case_title = lines[0]\n",
    "        case_type = lines[1]\n",
    "\n",
    "        if filter_unwanted_cases(case, case_title, case_type):\n",
    "            # Fields that can be found via pattern matching\n",
    "            if re.search('contributory negligence', case, re.IGNORECASE):\n",
    "                contributory_negligence_raised = 'Y'\n",
    "            else:\n",
    "                contributory_negligence_raised = 'N'\n",
    "            case_number = re.search(r'\\/P([0-9]+)\\.txt', path).group(1)\n",
    "            decision_len = re.search(r'\\(([0-9]+) paras\\.?\\)', case) # e.g.) (100 paras.)\n",
    "            registry = re.search(r'(Registry|Registries): ?([A-Za-z0-9 ]+)', case) # e.g.) Registry: Vancouver\n",
    "            written_decision = 'Y' if int(decision_len.group(1)) > 1 else 'N'\n",
    "            if registry:\n",
    "                registry = registry.group(2).strip()\n",
    "            else:\n",
    "                registry = re.search(r'([A-Za-z ]+) Registry No.', case) # Alt form e.g.) Vancouver Registory No. XXX\n",
    "                if registry:\n",
    "                    registry = registry.group(1).strip()\n",
    "                else:\n",
    "                    registry = re.search(r'([A-Za-z ]+) No. S[0-9]*', case)\n",
    "                    if registry:\n",
    "                        registry = registry.group(1).strip()\n",
    "                    else:\n",
    "                        print('WARNING: Registry could not be found (This shouldn\\'t occur!)')\n",
    "            # Fields that are always in the same place\n",
    "            judge_name = lines[4].strip()\n",
    "            case_title = lines[0].strip()\n",
    "            # Extract year from case_title (in case we want to make visualizations, etc.)\n",
    "            year = re.search(r'20[0-2][0-9]', case_title) # Limit regex to be from 2000 to 2029\n",
    "            if year:\n",
    "                year = year.group(0)\n",
    "            else:\n",
    "                # Rare case: Sometimes the title is too long. Rely on Heard date.\n",
    "                year = re.search(r'Heard:.* ([2][0][0-2][0-9])', case)\n",
    "                if year:\n",
    "                    year = year.group(1)\n",
    "                else:\n",
    "                    print('WARNING: Year not found')\n",
    "            case_dict['case_number'] = '%s of %s'%(i+1+((int(case_number)-1)*50), case_number)\n",
    "            case_dict['case_title'] = case_title\n",
    "            case_dict['year'] = year\n",
    "            case_dict['registry'] = registry\n",
    "            case_dict['judge'] = judge_name\n",
    "            case_dict['decision_length'] = decision_len.group(1)\n",
    "            case_dict['multiple_defendants'] = rule_based_multiple_defendants_parse(case)\n",
    "            case_dict['contributory_negligence_raised'] = contributory_negligence_raised\n",
    "            case_dict['written_decision'] = written_decision\n",
    "            \n",
    "            # TODO: Improve plaintiff_wins to take one case at a time.\n",
    "            case_dict['plaintiff_wins'] = plaintiff_wins(case)\n",
    "#             if case_title in plaintiff_list:\n",
    "#                 case_dict['plaintiff_wins'] = plaintiff_list[case_title]\n",
    "#             else:\n",
    "#                 case_dict['plaintiff_wins'] = \"NA\"\n",
    "            \n",
    "            if damage_model and damage_vectorizer:\n",
    "                predictions = predict(case, damage_model, damage_vectorizer)\n",
    "                case_dict['damages'] = assign_classification_damages(predictions)\n",
    "            else:\n",
    "                case_dict['damages'] = rule_based_damage_extraction(case)\n",
    "            \n",
    "            \n",
    "            percent_reduction, contributory_negligence_successful = get_percent_reduction_and_contributory_negligence_success(case_dict, case)\n",
    "            case_dict['percent_reduction'] = percent_reduction\n",
    "            case_dict['contributory_negligence_successful'] = contributory_negligence_successful\n",
    "             \n",
    "        \n",
    "        # don't add empty dictionaries (non BCJ cases) to list\n",
    "        if case_dict != dict(): \n",
    "            case_parsed_data.append(case_dict)\n",
    "    return case_parsed_data\n",
    "\n",
    "def rule_based_multiple_defendants_parse(doc):\n",
    "    ''' Helper function for rule_based_parse_BCJ\n",
    "    \n",
    "    Given a case. Uses regex/pattern-matching to determine whether we have multiple defendants.\n",
    "    For the most part the logic relies on whether the langauge used implies plurality or not.\n",
    "    \n",
    "    Arguments: doc (String): The case in text format following the form used in the DOCX to TXT notebook\n",
    "    Returns: response (String, 'Y', 'N', or 'UNK')\n",
    "    '''\n",
    "\n",
    "    # Case 1)\n",
    "    # Traditional/most common. Of form \"Between A, B, C, Plaintiff(s), X, Y, Z Defendant(s)\"\n",
    "    # Will also allow \"IN THE MATTER OF ... Plaintiff .... Defendant...\"\n",
    "    # Can successfully cover ~98% of data\n",
    "    regex_between_plaintiff_claimant = re.search(r'([Between|IN THE MATTER OF].*([P|p]laintiff[s]?|[C|c]laimant[s]?|[A|a]ppellant[s]?|[P|p]etitioner[s]?|[R|r]espondent[s]?).*([D|d]efendant[s]?|[R|r]espondent[s]?|[A|a]pplicant[s]?).*\\n)', doc)\n",
    "    \n",
    "    # Match found\n",
    "    if regex_between_plaintiff_claimant:\n",
    "        text = regex_between_plaintiff_claimant.group(0).lower()\n",
    "        if 'defendants' in text or 'respondents' in text or 'applicants' in text: # Defendant/respondent same thing.\n",
    "            return 'Y'\n",
    "        elif 'defendant' in text or 'respondent' in text or 'applicant' in text:\n",
    "            return 'N'\n",
    "    \n",
    "    # If not found, try other less common cases\n",
    "    else:\n",
    "        # Case 2)\n",
    "        # Sometimes it does not mention the name of the second item. (Defendent/Respondent)\n",
    "        # We can estimate if there are multiple based on the number of \",\" in the line (Covers all cases in initial data)\n",
    "        regex_missing_defendent = re.search(r'(Between.*([P|p]laintiff[s]?|[C|c]laimant[s]?|[A|a]ppellant[s]?|[P|p]etitioner[s]?).*\\n)', doc)\n",
    "        if regex_missing_defendent:\n",
    "            text = regex_missing_defendent.group(0).lower()\n",
    "            if len(text.split(',')) > 5:\n",
    "                return 'Y'\n",
    "            else:\n",
    "                return 'N'\n",
    "            \n",
    "        else:\n",
    "            print('Multiple defendants: Unknown! Unable to regex match')\n",
    "            return 'UNK'\n",
    "        \n",
    "def rule_based_damage_extraction(doc, min_score = 0.9, max_match_len_split = 10):\n",
    "    '''Helper function for rule_based_parse_BCJ\n",
    "    \n",
    "    Given a case, attempts to extract damages using regex patterns\n",
    "    \n",
    "    Arguments: doc (String): The case in text format following the form used in the DOCX to TXT notebook\n",
    "    min_score (float): The minimum paragraph score to consider having a valid $ number\n",
    "                       Paragraph has score 1 if its the last paragraph\n",
    "                       Paragraph has score 0 if its the first paragraph\n",
    "    max_match_len_split (int): The max amount of items that can appear in a regex match after splitting (no. words)\n",
    "    \n",
    "    Returns: damages (Dict): Contains any found damages\n",
    "    \n",
    "    '''\n",
    "    damages = defaultdict(float)\n",
    "    repetition_detection = defaultdict(set) # try to stem the repeated values\n",
    "    no_paras = re.search(r'\\(([0-9|,]+) paras?\\.?\\)', doc).group(1) # Get number of paragraphs\n",
    "    pattern = r'([.]?)(?=\\n[0-9]{1,%s}[\\xa0|\\s| ]{2})'%len(no_paras) # Used to split into paras\n",
    "    paras_split = re.split(pattern, doc)\n",
    "    money_patt = r'\\$[0-9|,]+' # Used to get all paragraphs with a money amount\n",
    "    scored_paras = [] # Score paragraphs based on where they appear in the document\n",
    "                      # Score of 0.0 would be the first paragraph. Score of 1.0 would be the last paragraph\n",
    "        \n",
    "    for i, paragraph in enumerate(paras_split):\n",
    "        if re.search(money_patt, paragraph):\n",
    "            scored_paras.append((i / len(paras_split), paragraph)) # (score, paragraph). Score formula: i/no_paras\n",
    "            \n",
    "    scored_paras = sorted(scored_paras, key=lambda x:x[0])[::-1] # Store from last paragraph to first\n",
    "    if len(scored_paras) == 0:\n",
    "        return None\n",
    "    if scored_paras[0][0] < min_score: #If highest scored paragraph is less than minimum score.\n",
    "        return None\n",
    "    \n",
    "    # Rule based dmg extraction REGEX patterns\n",
    "    regex_damages = r'[\\w|-]* ?(?:damage|loss|capacity|cost).+?\\$? ?[0-9][0-9|,|.]+[0-9]'\n",
    "    #regex_damages = r'(?:[\\w|-]* ?){0,3}(?:damage|loss|capacity|cost).+?\\$? ?[0-9][0-9|,|.]+[0-9]'\n",
    "    #regex_in_trust = r'(?:in-?trust|award).*?\\$? ?[0-9][0-9|,|.]+[0-9]'\n",
    "    #regex_damages = r'(?![and])(?:[\\w|-]* ?){0,2} ?(?:damage|loss|capacity|cost).+?\\$? ?[0-9][0-9|,|.]+[0-9]'\n",
    "    regex_damages_2 = r'[^:] \\$? ?[0-9][0-9|,|.]+[0-9] (?:for|representing)?[ \\w\\-+]+damages?'\n",
    "    regex_damages_3 = r'[^:] \\$? ?[0-9][0-9|,|.]+[0-9] (?:for|representing)?[ \\w\\-+]+damages?(?:(?:for|representing)?.*?[;.\\n])'\n",
    "    regex_future_care_loss = r'(?:future|past|in[-| ]?trust|award).*?(?:loss|costs?|income|care)?.*?\\$? ?[0-9][0-9|,|.]+[0-9]'\n",
    "    regex_for_cost_of = r'\\$? ?[0-9][0-9|,|.]+[0-9][\\w ]*? cost .*?\\.'\n",
    "\n",
    "    # Keywords to look in match for categorization\n",
    "    general_damage_keywords = [('general',), ('future', 'income', 'loss'), ('future', 'income'), ('future', 'wage', 'loss'), ('future', 'earning'), ('!past', 'earning', 'capacity'), ('future', 'capacity'), ('future', 'earning'), ('!past', 'loss', 'opportunity'), ('!past', 'loss', 'housekeep'), ('ei', 'benefit')]\n",
    "    special_damage_keywords = [('special',), ('trust',), ('past', 'income', 'loss'), ('past', 'wage'), ('past', 'earning'), ('past', 'income'), ('earning', 'capacity')]\n",
    "    aggravated_damage_keywords = [('aggravated',)]\n",
    "    non_pecuniary_damage_keywords = [('non', 'pecuniary')]\n",
    "    punitive_damage_keywords = [('punitive',)]\n",
    "    future_care_damage_keywords = [('future', 'care'), ('future', 'cost')]\n",
    "    \n",
    "    patterns = [regex_damages, regex_damages_2, regex_damages_3, regex_future_care_loss, regex_for_cost_of]\n",
    "    banned_words = ['seek', 'claim', 'propose', 'range', ' v. '] # Skip paragraphs containing these\n",
    "    counter_words = ['summary', 'dismissed'] # Unless these are mentioned. \n",
    "                                             # example) \"Special damage is $5k. But claims for aggravated are 'dismissed'\" \n",
    "    \n",
    "    # Get money mounts from the text\n",
    "    total = None\n",
    "    matches = []\n",
    "    summary_matches = []\n",
    "    for i, scored_para in enumerate(scored_paras):\n",
    "        text = scored_para[1]\n",
    "        score = scored_para[0]\n",
    "        \n",
    "        if score > min_score:\n",
    "            if any(item.startswith('summary') for item in text.lower().split()[:4]) or any(item.startswith('conclusion') for item in text.lower().split()[:4]):\n",
    "                text_matches = get_matching_text(patterns, text, max_match_len_split)\n",
    "                for t_m in text_matches:\n",
    "                    summary_matches.append((score, t_m))\n",
    "            elif i+1 < len(scored_paras) and (any(item.startswith('summary') for item in scored_paras[i+1][1].lower().split()[-4:]) or any(item.startswith('conclusion') for item in scored_paras[i+1][1].lower().split()[-4:])):\n",
    "                text_matches = get_matching_text(patterns, text, max_match_len_split)\n",
    "                for t_m in text_matches:\n",
    "                    summary_matches.append((score, t_m))\n",
    "            else:\n",
    "                skip = False # Skip paras with banned words\n",
    "                for banned_word in banned_words: \n",
    "                    if banned_word in text:\n",
    "                        skip = True       \n",
    "                for counter_word in counter_words:\n",
    "                    if counter_word in text:\n",
    "                        skip = False\n",
    "                if skip:\n",
    "                    continue\n",
    "\n",
    "                text_matches = get_matching_text(patterns, text, max_match_len_split)\n",
    "                for t_m in text_matches:\n",
    "                    matches.append((score, t_m))\n",
    "        \n",
    "    # Only keep matches from the summary if a summary was found. If not keep all matches.\n",
    "    if len(summary_matches) > 0: \n",
    "        matches = summary_matches\n",
    "\n",
    "    # Extract $ value. Determine correct column\n",
    "    regex_number_extraction = r' ?[0-9][0-9|,|.]+[0-9]'\n",
    "    for score, match in matches:\n",
    "        skip = False # Banned words should not appear in final matches\n",
    "        for banned_word in banned_words: \n",
    "            if banned_word in match:    \n",
    "                skip = True\n",
    "                break\n",
    "        if skip:\n",
    "            continue\n",
    "        \n",
    "        amount = re.findall(regex_number_extraction, match, re.IGNORECASE)\n",
    "        extracted_value = clean_money_amount(amount)\n",
    "        if extracted_value is None: # Make sure we are able to extract a value\n",
    "            continue\n",
    "            \n",
    "        value_mapped = False # If we mapped the value into a damage category - stop trying to map into other categories\n",
    "        value_mapped = assign_damage_to_category(extracted_value, general_damage_keywords, match, score, matches, 'General', damages, repetition_detection, repetition_key = ('general',))\n",
    "        if not value_mapped:\n",
    "            value_mapped = assign_damage_to_category(extracted_value, special_damage_keywords, match, score, matches, 'Special', damages, repetition_detection, repetition_key = ('special',))\n",
    "        if not value_mapped:\n",
    "            value_mapped = assign_damage_to_category(extracted_value, non_pecuniary_damage_keywords, match, score, matches, 'Non-pecuniary', damages, repetition_detection, repetition_key = ('non','pecuniary'))\n",
    "        if not value_mapped:\n",
    "            value_mapped = assign_damage_to_category(extracted_value, aggravated_damage_keywords, match, score, matches, 'Aggravated', damages, repetition_detection, repetition_key = ('aggravated',))\n",
    "        if not value_mapped:\n",
    "            value_mapped = assign_damage_to_category(extracted_value, punitive_damage_keywords, match, score, matches, 'Punitive', damages, repetition_detection, repetition_key = ('punitive',))\n",
    "        if not value_mapped:\n",
    "            value_mapped = assign_damage_to_category(extracted_value, future_care_damage_keywords, match, score, matches, 'Future Care', damages, repetition_detection) \n",
    "        if not value_mapped: # Last attempt: Only use \"total amounts\" if nothing else was found\n",
    "            total_keywords = [('total',), ('sum',), ('award',)]\n",
    "            for keywords in total_keywords:\n",
    "                if match_contains_words(match.lower(), keywords):\n",
    "                    if is_best_score(score, matches, keywords):\n",
    "                        if extracted_value not in repetition_detection[('total',)]:\n",
    "                            damages['Pecuniary Total'] = damages['Special'] + damages['General'] + damages['Punitive'] + damages['Aggravated'] + damages['Future Care']\n",
    "                            damages['Total'] = damages['Pecuniary Total'] + damages['Non-pecuniary']\n",
    "                            if damages['Total'] == 0:\n",
    "                                total = extracted_value\n",
    "                                repetition_detection[('total',)].add(extracted_value)\n",
    "                        \n",
    "    damages['Pecuniary Total'] = damages['Special'] + damages['General'] + damages['Punitive'] + damages['Aggravated'] + damages['Future Care']\n",
    "    damages['Total'] = damages['Pecuniary Total'] + damages['Non-pecuniary']\n",
    "    \n",
    "    if damages['Total'] == 0 and total is not None: # Only use the \"total\" if we couldnt find anything else!\n",
    "        damages['Total'] = total\n",
    "        damages['General'] = total\n",
    "        \n",
    "    columns = ['Total', 'Pecuniary Total', 'Non-pecuniary', 'Special', 'General', 'Punitive', 'Aggravated', 'Future Care']\n",
    "    for c in columns:\n",
    "        damages[c] = None if damages[c] == 0 else damages[c]\n",
    "    \n",
    "    return damages\n",
    "\n",
    "def assign_damage_to_category(damage, damage_keywords, match, match_score, matches, damage_type, damage_dict, repetition_dict, repetition_key = None):\n",
    "    '''Helper function for rule based damage extraction.\n",
    "    \n",
    "    Adds damage to dictionary based on given parameters so long as it is the\n",
    "    highest scoring match & doesn't appear in the repetition dictionary\n",
    "    \n",
    "    Argumets:\n",
    "    damage (float) - The damage amount in the match\n",
    "    damage_keywords (list) - Keywords that may appear in match\n",
    "    match (string) - The match string itself\n",
    "    matches (list) - All matches. Used to determine if we found the best match\n",
    "    damage_dict (dict) - Dictionary storing all damages\n",
    "                       - Will be modified in place\n",
    "    repetition_dict (dict) - Dictionary storing repeated values\n",
    "                           - Will be modified in place\n",
    "    (Optional) repetition_key (Tuple) - If not none, will use this key to store repetitions. Else will use matching keyword\n",
    "    \n",
    "    Returns:\n",
    "    value_belongs (Boolean) - True if the value belongs in the given keyword category. False otherwise\n",
    "    '''\n",
    "    match = match.lower()\n",
    "    value_belongs = False\n",
    "    \n",
    "    for keywords in damage_keywords:\n",
    "        if match_contains_words(match, keywords):\n",
    "            value_belongs = True\n",
    "            if is_best_score(match_score, matches, keywords):\n",
    "                if damage not in repetition_dict[repetition_key if repetition_key else keywords]:\n",
    "                    damage_dict[damage_type] += damage\n",
    "                    repetition_dict[repetition_key if repetition_key else keywords].add(damage)\n",
    "            break\n",
    "    \n",
    "    return value_belongs\n",
    "\n",
    "def clean_money_amount(money_regex_match):\n",
    "    '''Helper function for rule based damage extraction.\n",
    "    \n",
    "    Arguments:\n",
    "    money_regex_match (Regex.findall object) - Match of $ amount\n",
    "    \n",
    "    Returns:\n",
    "    None if a bad match\n",
    "    extracted_value (float) - The money amount in float form\n",
    "    '''\n",
    "    # If our regex contains more than 1 or 0 money values. We cannot use the match.\n",
    "    if len(money_regex_match) > 1:\n",
    "        return None\n",
    "    if len(money_regex_match) == 0:\n",
    "        print('Error: No Money in match!', match)\n",
    "        return None\n",
    "\n",
    "    extracted_value = None\n",
    "    amount = money_regex_match[0].replace(',' , '')\n",
    "    amount = amount.replace(' ' , '')\n",
    "    # Deals with money at end of sentence. example) ... for '5,000.00.' -> '5000.00'\n",
    "    if amount[-1] == '.': \n",
    "        amount = amount[:-1]\n",
    "    # Deals with quantities such as $2.5 million\n",
    "    if 'million' in amount or amount[-1] == 'm':\n",
    "        amount = str(float(re.findall('[0-9|\\.]+', amount)[0])*10e6)\n",
    "    # Deals with a rare typo in some cases. example) 50.000.00 -> 50000.00\n",
    "    if amount.count('.') > 1: \n",
    "        dot_count = amount.count('.')\n",
    "        changes_made = 0\n",
    "        new_amount = ''\n",
    "        for letter in amount:\n",
    "            if letter == '.' and changes_made != dot_count-1:\n",
    "                changes_made += 1\n",
    "            else:\n",
    "                new_amount += letter\n",
    "        amount = new_amount\n",
    "    extracted_value = float(amount)\n",
    "    return extracted_value\n",
    "\n",
    "def get_matching_text(patterns, text, max_match_len_split):\n",
    "    '''Helper function for rule based damage extraction.\n",
    "    \n",
    "    Given a set of regex; pulls out all matching text\n",
    "    \n",
    "    Arguments:\n",
    "    patterns (list) - List of regex patterns in string format\n",
    "    text (string) - Text to search for matches in\n",
    "    \n",
    "    Returns:\n",
    "    matches (list) - List containing all matches in text format\n",
    "    '''\n",
    "\n",
    "    matches = []\n",
    "    for pattern in patterns:\n",
    "        for match in re.findall(pattern, text, re.IGNORECASE):\n",
    "            if 'and' not in match:\n",
    "                if len(match.split()) <= max_match_len_split:\n",
    "                    matches.append(match)\n",
    "                    \n",
    "    return matches\n",
    "\n",
    "def is_best_score(score, matches, keywords):\n",
    "    '''Helper function for rule based damage extraction.\n",
    "    \n",
    "    Given a set of regex matches, determine if the score is the highest score out of all matches for the given keywords\n",
    "    Score is from 0 - 1; describes where in the paragraph the match was found\n",
    "    Score is 1 if the match came from the final paragraph\n",
    "    Score is 0 if the match came from the first paragraph\n",
    "    \n",
    "    Arguments:\n",
    "    score (float) - The score of the item you're inspecting\n",
    "    matches (list) - List of matches where each element is of form (score, match text)\n",
    "    keywords (tuple) - All words that should appear in the match\n",
    "    \n",
    "    Returns: True or False\n",
    "    \n",
    "    '''\n",
    "    best_score = score\n",
    "    \n",
    "    for score, match in matches:\n",
    "        if all(word in match.lower() for word in keywords):\n",
    "            if score > best_score:\n",
    "                return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "# TODO: This function should be updated by Niki\n",
    "def plaintiff_wins(case):\n",
    "    '''This function will search the cases and returns a dictionary\n",
    "    with case names as keys and boolean for value, True if the plaintiff\n",
    "    wins the case and False if plaintiff looses'''\n",
    "\n",
    "    # regex search for keyword HELD in cases, which determines if case was allowed or dismissed\n",
    "    lines = case.strip().split('\\n')\n",
    "    HELD = re.search(r'HELD.+', case)\n",
    "    if HELD:\n",
    "        matched = HELD.group(0)\n",
    "        if \"allowed\" in matched or \"favour\" in matched or \"awarded\" in matched:\n",
    "            return 'Y'\n",
    "        if \"dismissed\" in matched:\n",
    "            return 'N'\n",
    "        \n",
    "        \n",
    "    awarded =  re.search(r'award(.+)?.+?(plaintiff(.+)?)?', lines[-2])\n",
    "    #regex searches for pattern of plaintiff/defendant/applicant....entitled/have...costs\n",
    "    entiteled = re.search(r'(plaintiff|defendant.?|applicant)(.+)?(entitle(.)?(.+)?|have).+?cost(.+)?', lines[-2])\n",
    "    #regex searches for pattern of successful...(case)\n",
    "    successful = re.search(r'successful(.+)?.+?', lines[-2])\n",
    "    #regex searches for dismiss....\n",
    "    dismiss = re.search(r'dismiss(.+)?.+', lines[-2])\n",
    "    costs = re.search(r'costs.+?(award(.+)?|cause).+?', lines[-2])\n",
    "\n",
    "    if dismiss and \"not dismissed\" not in lines[-2]:\n",
    "        return 'N'\n",
    "    elif awarded:\n",
    "        return 'Y'\n",
    "    elif entiteled:\n",
    "        return 'Y'\n",
    "    elif successful:\n",
    "        return 'Y'\n",
    "    elif costs:\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return \"OpenCase\" \n",
    "\n",
    "def match_contains_words(match, words):\n",
    "    '''Helper function for rule based damage extraction.\n",
    "    \n",
    "    Given some text. Find if the words are all present in the text.\n",
    "    If word begins with '!' the word cannot appear in the text, acts as a negation. \n",
    "    Can handle mix/matching of both types.\n",
    "    \n",
    "    Example: ('!good', 'day') would match any string with the word \"day\" present and \"good\" NOT present.\n",
    "    \n",
    "    Arguments:\n",
    "    match (String) - The text to look for words in\n",
    "    words (list) - List of words to check for. If word begins with ! (i.e. '!past'), then the word cannot appear in it\n",
    "    \n",
    "    Returns:\n",
    "    True if all words are present (or not present if using !)\n",
    "    False otherwise\n",
    "    \n",
    "    '''\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    for word in words:\n",
    "        if word.startswith('!'):\n",
    "            neg_words.append(word[1:])\n",
    "        else:\n",
    "            pos_words.append(word)\n",
    "            \n",
    "    if all(word in match for word in pos_words):\n",
    "        if all(word not in match for word in neg_words):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def filter_unwanted_cases(case, case_title, case_type):\n",
    "    '''Given a case, its title & type, determines whether the case\n",
    "    is relevant or not for our analysis\n",
    "    \n",
    "    Removes crown cases 'R.v.'\n",
    "    Removes '(Re)' cases\n",
    "    Removes client-solicitor cases\n",
    "    Removes IN THE MATTER OF cases where plaintiff/defendant is not mentioned\n",
    "    Removes non 'British Columbia Judgments' cases\n",
    "    \n",
    "    Arguments:\n",
    "    case (string) - Case data in string form\n",
    "    case_title (string) - Case title (line 1 of case)\n",
    "    case_type (string) - Case type (line 2 of case)\n",
    "    \n",
    "    Returns:\n",
    "    boolean - True if case should be analyzed. False if it should be skipped.\n",
    "    '''\n",
    "    \n",
    "    if 'R. v.' in case_title or '(Re)' in case_title: # Skip crown cases, Skip (Re) cases\n",
    "        return False\n",
    "\n",
    "    # Skip client/solicitor cases (not same as plaintiff/defendant)\n",
    "    regex_client_solicitor = re.search(r'(Between.*([C|c]lient[s]?).*([S|s]olicitor[s]?|[L|l]awyer[s]?))', case)\n",
    "    if regex_client_solicitor:\n",
    "        return False\n",
    "\n",
    "    regex_solicitor_client = re.search(r'(Between.*([L|l]awyer[s]?|[S|s]olicitor[s]?).*([C|c]lient[s]?))', case)\n",
    "    if regex_solicitor_client:\n",
    "        return False\n",
    "\n",
    "    # In some rare cases we have 'IN THE MATTER OF ..' (rather than 'Between ...') .. but it is following by the normal\n",
    "    # plaintiff/defendant dynamic. Only skip cases if there is no mention of the following terms\n",
    "    # (Can be cleaned up in future)\n",
    "    key_words = ['appellant', 'respondent', 'claimant', 'petitioner', 'plaintiff', 'defendant',\n",
    "    'appellants', 'respondents', 'claimants', 'petitioners', 'plaintiffs', 'defendants']\n",
    "    regex_in_matter_of = re.search(r'IN THE MATTER OF .*\\n\\([0-9]+ paras.\\)', case)\n",
    "    if regex_in_matter_of:\n",
    "        remove = True\n",
    "        for key in key_words:\n",
    "            if key in regex_in_matter_of.group(0).lower().strip():\n",
    "                remove = False\n",
    "\n",
    "        if remove:\n",
    "            return False\n",
    "\n",
    "    if 'British Columbia Judgments' in case_type:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def paragraph_tokenize(case):\n",
    "    ''' Takes string input the of wntire document (case) and returns list of lists of paragraphs in the document.\n",
    "    ---------\n",
    "    Input: case (str) - string of single legal case\n",
    "    Return: case_data(list) - list of of numbrered paragraphs in the document where the first item is the case_title'''\n",
    "    \n",
    "    case_data = []\n",
    "    lines = case.split('\\n')\n",
    "    if not 'British Columbia Judgments' in lines[1]:\n",
    "        return\n",
    "    case_data.append(lines[0])\n",
    "    decision_length = re.search(r'\\(([0-9|,]+) paras?\\.?\\)', case).group(1)\n",
    "\n",
    "    # split paragraphs on newline, paragraph number, two spaces\n",
    "    pattern = r'.?(?=\\n[0-9]{1,%s}[\\xa0]{2})'%len(decision_length)\n",
    "    paras_split = re.split(pattern, case)\n",
    "\n",
    "    paras = []\n",
    "    for para in paras_split:   \n",
    "        # make sure the paragraph starts with the correct characters\n",
    "        para_start = re.match(r'^\\n([0-9]{1,%s})[\\xa0]{2}'%len(decision_length), para)\n",
    "        if para_start:\n",
    "            paras.append(para)\n",
    "    case_data.extend(paras)\n",
    "    return case_data\n",
    "\n",
    "def summary_tokenize(case):\n",
    "    ''' String of Entire Document and returns the document summary and HELD section.\n",
    "    ---------\n",
    "    Input: case (str) - string of single legal case\n",
    "    Return: summary - summary and HELD section of case (str)'''\n",
    "    \n",
    "    lines = case.split('\\n')\n",
    "    if not 'British Columbia Judgments' in lines[1]:\n",
    "        return\n",
    "    \n",
    "    # split paragraphs on newline, paragraph number, two spaces\n",
    "    summary = re.search(r'\\([0-9]{1,3} paras\\.\\)\\ncase summary\\n((.*\\n+?)+)(?=HELD|(Statutes, Regulations and Rules Cited:)|(Counsel\\n))', case, re.IGNORECASE)\n",
    "    if summary:\n",
    "        summary = summary.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return summary\n",
    "\n",
    "def get_context_and_float(value, text, context_length = 8, plaintiff_name = 'Plaintiff', defendant_name = 'Defendant'):\n",
    "    '''Given a string value found in a body of text, \n",
    "    return its context, and its float equivalent.\n",
    "    -----------------\n",
    "    Arguments:\n",
    "    value - percent match found in text\n",
    "    text - string value where matches were extracted from, eg paragraph or summary (str)\n",
    "    context_length - the length of context around each quantity to return\n",
    "    Rerturn:\n",
    "    value_context - string of context around value (str)\n",
    "    extracted_value - string quantity value extracted to its float equivalent'''\n",
    "    \n",
    "    \n",
    "    # get context for monetary/percent values \n",
    "    context = ''\n",
    "    amount = re.findall(r'[0-9]+[0-9|,]*(?:\\.[0-9]+)?', value)\n",
    "    extracted_value = clean_money_amount(amount) #use helper function to get float of dollar/percent value\n",
    "    if not extracted_value:\n",
    "        print('ERROR: cant convert string, %s'%value)\n",
    "        return context, None\n",
    "    # get indices of last instance of value in text - tokenize like this for values of type 'per cent and percent'\n",
    "    start_idx = text.rfind(value)\n",
    "    if start_idx == -1:\n",
    "        print('ERROR: value not in text')\n",
    "    end_idx = start_idx + len(value)\n",
    "    tokens = text[:start_idx].split() + [value] + text[end_idx:].split()\n",
    "    \n",
    "    # get indices of quantity value in text\n",
    "    loc = [i for i, token in enumerate(tokens) if value in token] \n",
    "    \n",
    "    # if the quantity is in the text, choose context of last mention of value\n",
    "    if len(loc) > 0:\n",
    "        loc = loc[-1] \n",
    "        if loc - context_length >= 0 and loc + context_length < len(tokens):\n",
    "            context = \" \".join(tokens[loc - context_length:loc + context_length + 1])\n",
    "        elif loc - context_length < 0 and loc + context_length < len(tokens):\n",
    "            beg = abs(loc -context_length)\n",
    "            context = \" \".join(tokens[loc-context_length + beg:loc + context_length + 1])\n",
    "        elif loc - context_length > 0 and loc + context_length > len(tokens): \n",
    "            context = \" \".join(tokens[loc - context_length:len(tokens)])\n",
    "\n",
    "    return context.lower(), extracted_value\n",
    "\n",
    "def conditions_for_extracted_value(context, extracted_value, keywords, plaintiff_split, defendant_split, entities):\n",
    "    ''' Given the context surrounding an extracted value (percent), keywords relevant to contributory negligence (ie liability, approtion, fault, etc), \n",
    "    a list of the Plaintiffs names (ie John Doe), a list of the defendants names, and a combined list of entities(ie plaintiff, john, doe, defendant):\n",
    "    Return: the modifed extracted value (float)\n",
    "    ------------\n",
    "    Arugments:\n",
    "    context: (str)\n",
    "    extracted_value: (float) found in context\n",
    "    keywords, plaintiff_split, defendant_split, entities: (list) of strings\n",
    "    ------------\n",
    "    Example:\n",
    "    context = 'the defendant is responsible for 30% of damages'\n",
    "    extracted_value = 30.0\n",
    "    keywords = ['fault', 'liable', 'liability', 'apportion', 'contributor', 'recover', 'responsible']\n",
    "    plaintiff_split = ['john', 'doe']\n",
    "    defendant_split = ['jane', 'smith']\n",
    "    entities = ['plaintiff', 'defendant', 'john', 'jane', 'doe', 'smith']\n",
    "    conditions_for_extracted_value(context, extracted_value, \n",
    "                        keywords, plaintiff_split, defendant_split) = 70.0\n",
    "    '''\n",
    "    # conditions for keeping extracted_value and updating extracted_value\n",
    "    # skip extracted_values with contexts lacking keywords/entities\n",
    "    if extracted_value == 100 or extracted_value == 0 or extracted_value < 10:\n",
    "        return\n",
    "    if not any(token in context for token in keywords + entities) or context == '' or any('costs' == token for token in context.split()) or ('interest' in context and 'rate' in context.split()):\n",
    "        return \n",
    "    if 'recover' in context and any(word in context for word in plaintiff_split + ['plaintiff']):\n",
    "        extracted_value = 100 - extracted_value\n",
    "    if any(word1 in context and word2 in context for word1 in defendant_split + ['defendant'] for word2 in ['liable', 'responsible', 'fault', 'against']):\n",
    "        extracted_value = 100 - extracted_value\n",
    "    return extracted_value\n",
    "\n",
    "def contributory_negligence_successful_fun(context, keywords):\n",
    "    '''Given text containing percent reduction and a list of keywords to check for,\n",
    "    confirm presence of keywords and return whether or not contributory negligence was successful\n",
    "    --------------\n",
    "    Arguments:\n",
    "    context (str)\n",
    "    keywords(list)\n",
    "    Returns: True or None (bool)'''\n",
    "    if any(word in context for word in keywords):\n",
    "        if 'plaintiff' or 'damages' or 'defendant' in context:\n",
    "            contributory_negligence_successful = True\n",
    "            return contributory_negligence_successful\n",
    "    return\n",
    "\n",
    "def get_percent_reduction_and_contributory_negligence_success(case_dict, case, min_score = 0.9):\n",
    "    paragraphs = paragraph_tokenize(case)\n",
    "    case_title = case_dict['case_title']\n",
    "    assert paragraphs[0] == case_title\n",
    "    \n",
    "    # default value for contributory negligence success is FALSE\n",
    "    contributory_negligence_successful = False\n",
    "    percent_pattern = r'([0-9][0-9|\\.]*(?:%|\\sper\\s?cent))'\n",
    "    \n",
    "    # entities and keywords used to filter percent values\n",
    "    keywords = ['against', 'reduce', 'liability', 'liable', 'contributor', 'fault', 'apportion', 'recover', 'responsible']\n",
    "    # extract plaintiff and defendant name for use in %reduction conditions\n",
    "    plaintiff_defendant_pattern = r'([A-Za-z|-|\\.]+(:? \\(.*\\))?)+ v\\. ([A-Za-z|-]+)+' # group 1 is plaintiff group 2 is defendant\n",
    "    if re.search(plaintiff_defendant_pattern, case_title):\n",
    "        plaitiff_defendant = re.search(plaintiff_defendant_pattern, case_title).groups() # tuple (plaintiff, defendant)\n",
    "    else:\n",
    "        plaitiff_defendant = ('Plaintiff', 'Defendant')\n",
    "    plaintiff_split = [word.lower() for word in plaitiff_defendant[0].split()]\n",
    "    defendant_split = [word.lower() for word in plaitiff_defendant[-1].split()]\n",
    "    entities = ['defendant', 'plaintiff'] + plaintiff_split + defendant_split \n",
    "\n",
    "    if case_dict['contributory_negligence_raised'] and case_dict['plaintiff_wins']:\n",
    "        percent_reduction = None\n",
    "        best_percent = None\n",
    "        best_score = 0\n",
    "        for j, paragraph in enumerate(paragraphs[1:]):\n",
    "            score = float((j+1)/int(case_dict['decision_length']))\n",
    "            paragraph = paragraph.lower()\n",
    "            if not score >= min_score: ## min score not existant in bcj parser\n",
    "                continue\n",
    "\n",
    "            percent_mentioned = re.findall(percent_pattern, paragraph, re.IGNORECASE)\n",
    "            extracted_value_tie_breaker = Counter()\n",
    "            if len(percent_mentioned) > 0:\n",
    "                for percent in percent_mentioned:\n",
    "                    context, extracted_value = get_context_and_float(percent, paragraph)\n",
    "                    # conditions for keeping extracted_value and updating extracted_value\n",
    "                    # skip extracted_values with contexts lacking keywords/entities\n",
    "                    if context == '':\n",
    "                        continue\n",
    "                    extracted_value = conditions_for_extracted_value(context, extracted_value, keywords, plaintiff_split, defendant_split, entities)\n",
    "                    if not extracted_value:\n",
    "                        continue\n",
    "                        \n",
    "                    extracted_value_tie_breaker.update([extracted_value])\n",
    "                \n",
    "                    # conditions for contributory negligence successful\n",
    "                    if not contributory_negligence_successful and extracted_value:\n",
    "                        contributory_negligence_successful = contributory_negligence_successful_fun(context, keywords)\n",
    "\n",
    "                    # matches patter \"PERCENT against plaintiff\"\n",
    "                    if ('against' in context or 'fault' in context) and any(plaintiff_word in context for plaintiff_word in plaintiff_split+['plaintiff']):\n",
    "                        best_percent = extracted_value\n",
    "                        best_score = score\n",
    "                        break                    \n",
    "                    \n",
    "                    # choose most common percent mentioned in highest scoring paragraph\n",
    "                    if extracted_value_tie_breaker != Counter():\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_percent = extracted_value_tie_breaker.most_common(1)[0][0]\n",
    "\n",
    "             # if no percent found, check for equal apportionment\n",
    "            else:\n",
    "                equal_apportionment = re.findall(r'.{20} (?:liability|fault) [a-zA-Z]{1,3} apportione?d? equally .{20}', paragraph)\n",
    "                if len(equal_apportionment) > 0:\n",
    "                    if contributory_negligence_successful_fun(equal_apportionment[0], keywords):\n",
    "                        best_percent = 50.0\n",
    "                        contributory_negligence_successful = True\n",
    "        \n",
    "        if best_score == 0 or not best_percent or not contributory_negligence_successful:\n",
    "            # no percents found in paragraphs - time to check summary - same process\n",
    "            summary = summary_tokenize(case)\n",
    "            if summary:\n",
    "                summary = summary.lower()\n",
    "                percent_mentioned = re.findall(percent_pattern, summary, re.IGNORECASE)\n",
    "                extracted_value_tie_breaker = Counter()\n",
    "                if len(percent_mentioned) > 0:\n",
    "                    for percent in percent_mentioned:\n",
    "                        context, extracted_value = get_context_and_float(percent, summary)\n",
    "                        # conditions for keeping extracted_value and updating extracted_value\n",
    "                        # skip extracted_values with contexts lacking keywords/entities\n",
    "                        extracted_value = conditions_for_extracted_value(context, extracted_value, keywords, plaintiff_split, defendant_split, entities)\n",
    "                        if not extracted_value:\n",
    "                            continue\n",
    "                        extracted_value_tie_breaker.update([extracted_value])\n",
    "                                                   \n",
    "                        # conditions for contributory negligence successful\n",
    "                        if not contributory_negligence_successful and extracted_value:\n",
    "                            contributory_negligence_successful = contributory_negligence_successful_fun(context, keywords) \n",
    "                            \n",
    "                        # matches patter \"PERCENT against plaintiff\"\n",
    "                        if ('against' in context or 'fault' in context) and any(plaintiff_word in context for plaintiff_word in plaintiff_split+['plaintiff']):\n",
    "                            best_percent = extracted_value\n",
    "                            best_score = score\n",
    "                            break \n",
    "                        # choose most common percent mentioned in summary\n",
    "                        if extracted_value_tie_breaker != Counter():\n",
    "                            best_percent = extracted_value_tie_breaker.most_common(1)[0][0]\n",
    "\n",
    "               # if no percent found, check for equal apportionment\n",
    "                else:\n",
    "                    equal_apportionment = re.findall(r'.{20} (?:liability|fault) [a-zA-Z]{1,3} apportione?d? equally .{20}', summary)\n",
    "                    if len(equal_apportionment) > 0:\n",
    "                        if contributory_negligence_successful_fun(equal_apportionment[0], keywords):\n",
    "                            best_percent = 50.0\n",
    "                            contributory_negligence_successful = True\n",
    "        if contributory_negligence_successful:\n",
    "            percent_reduction = best_percent\n",
    "    else:\n",
    "        percent_reduction = None\n",
    " \n",
    "    return percent_reduction, contributory_negligence_successful\n",
    "\n",
    "def train_classifier(path, clf = MultinomialNB()):\n",
    "    '''Trains a classifier based on the given training data path\n",
    "    \n",
    "    Arguments:\n",
    "    path (String) - Path to .txt containing training data\n",
    "    clf - untrained sklearn classifier, ie MultinomialNB()\n",
    "    \n",
    "    Returns:\n",
    "    model (sklearn model) - Trained model\n",
    "    vectorizer (sklearn DictVectorizer) - fit-transformed vectorizer\n",
    "    '''\n",
    "    tag_extractor = re.compile('''<damage type ?= ?['\"](.*?)['\"]> ?(\\$?.*?) ?<\\/damage>''')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    with open(path, encoding='utf-8') as document:\n",
    "        document_data = document.read()\n",
    "        \n",
    "    document_data = document_data.split('End of Document\\n')\n",
    "        \n",
    "    \n",
    "    examples_per_case = [] # Each element contains all examples in a case\n",
    "    answers_per_case = [] # Each element contains all answers in a case \n",
    "    num_cases = len(document_data)\n",
    "    for i in range(len(document_data)):\n",
    "        \n",
    "            \n",
    "        print('Reading training data and extracting features...', i / num_cases * 100, '%', end='\\r')\n",
    "        case = document_data[i]\n",
    "        case = case.strip() # Make sure to strip!\n",
    "        if len(case) == 0: # Skip empty lines\n",
    "            continue\n",
    "        \n",
    "        lines = case.split('\\n')\n",
    "        case_title = lines[0]\n",
    "        try:\n",
    "            case_type = lines[1]\n",
    "        except:\n",
    "            print(case)\n",
    "            \n",
    "        if case_title.startswith('Chamberlain v. Pro'):\n",
    "            print('Hit last train case\\n\\n\\n')\n",
    "            break\n",
    "        \n",
    "        # lower case and remove stopwords\n",
    "        case = ' '.join([word for word in case.lower().split() if word not in stop_words])\n",
    "        \n",
    "        case_examples = []\n",
    "        case_answers = []\n",
    "        if filter_unwanted_cases(case, case_title, case_type):\n",
    "            matches = tag_extractor.finditer(case) # Extract all <damage ...>$x</damage> tags used for training\n",
    "            for match in matches:\n",
    "                features, answer = extract_features(match, case, tag_extractor)\n",
    "                case_examples.append(features)\n",
    "                case_answers.append(answer)\n",
    "                \n",
    "        if len(case_examples) > 0 and len(case_answers) > 0:\n",
    "            examples_per_case.append(case_examples)\n",
    "            answers_per_case.append(case_answers)\n",
    "        else:\n",
    "            print('Didnt find any tags in', case_title)\n",
    "                    \n",
    "    print('\\nVectorizing...')    \n",
    "    vectorizer = DictVectorizer()\n",
    "    feats = list(chain.from_iterable(examples_per_case)) # Puts it into one big list\n",
    "    X = vectorizer.fit_transform(feats)\n",
    "    y = list(chain.from_iterable(answers_per_case))\n",
    "    \n",
    "    print('Tag Distribution')\n",
    "    dist = Counter(y)\n",
    "    print(dist)\n",
    "    \n",
    "    print('Cross validation evaluation...')\n",
    "    #print('Scores (F1-MACRO):', np.mean(cross_val_score(clf, X, y, cv = 5, scoring = 'f1_macro')))\n",
    "    #print('Scores (F1-MICRO):', np.mean(cross_val_score(clf, X, y, cv = 5, scoring = 'f1_micro')))\n",
    "    #print('Scores (F1-WEIGHTED):', np.mean(cross_val_score(clf, X, y, cv = 5, scoring = 'f1_weighted')))\n",
    "    \n",
    "    y_pred = cross_val_predict(clf, X, y, cv=3)\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    print('Training final model...')\n",
    "    clf.fit(X, y)\n",
    "    return clf, vectorizer\n",
    "\n",
    "def train_CN_classifier(path, clf = MultinomialNB()):\n",
    "    '''Trains a classifier based on the given training data path\n",
    "    \n",
    "    Arguments:\n",
    "    path (String) - Path to .txt containing training data\n",
    "    clf - untrained sklearn classifier, ie MultinomialNB()\n",
    "    \n",
    "    Returns:\n",
    "    model (sklearn model) - Trained model\n",
    "    vectorizer (sklearn DictVectorizer) - fit-transformed vectorizer\n",
    "    '''\n",
    "    tag_extractor = re.compile('''<percentage type ?= ?['\"](.*?)['\"]> ?(\\$?.*?) ?<\\/percentage>''')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    with open(path, encoding='utf-8') as document:\n",
    "        document_data = document.read()\n",
    "        \n",
    "    document_data = document_data.split('End of Document\\n')\n",
    "        \n",
    "    \n",
    "    examples_per_case = [] # Each element contains all examples in a case\n",
    "    answers_per_case = [] # Each element contains all answers in a case \n",
    "    num_cases = len(document_data)\n",
    "    for i in range(len(document_data)):\n",
    "        \n",
    "            \n",
    "        print('Reading training data and extracting features...', i / num_cases * 100, '%', end='\\r')\n",
    "        case = document_data[i]\n",
    "        case = case.strip() # Make sure to strip!\n",
    "        if len(case) == 0: # Skip empty lines\n",
    "            continue\n",
    "        \n",
    "        lines = case.split('\\n')\n",
    "        case_title = lines[0]\n",
    "        try:\n",
    "            case_type = lines[1]\n",
    "        except:\n",
    "            print(case)\n",
    "            \n",
    "        #if case_title.startswith('Chamberlain v. Pro'):\n",
    "        #    print('Hit last train case\\n\\n\\n')\n",
    "        #    break\n",
    "        \n",
    "        # lower case and remove stopwords\n",
    "        case = ' '.join([word for word in case.lower().split() if word not in stop_words])\n",
    "        \n",
    "        case_examples = []\n",
    "        case_answers = []\n",
    "        if filter_unwanted_cases(case, case_title, case_type):\n",
    "            matches = tag_extractor.finditer(case) # Extract all <damage ...>$x</damage> tags used for training\n",
    "            for match in matches:\n",
    "                features, answer = extract_CN_features(match, case, tag_extractor)\n",
    "                case_examples.append(features)\n",
    "                case_answers.append(answer)\n",
    "                \n",
    "        if len(case_examples) > 0 and len(case_answers) > 0:\n",
    "            examples_per_case.append(case_examples)\n",
    "            answers_per_case.append(case_answers)\n",
    "        else:\n",
    "            print('Didnt find any tags in', case_title)\n",
    "                    \n",
    "    print('\\nVectorizing...')    \n",
    "    vectorizer = DictVectorizer()\n",
    "    feats = list(chain.from_iterable(examples_per_case)) # Puts it into one big list\n",
    "    X = vectorizer.fit_transform(feats)\n",
    "    y = list(chain.from_iterable(answers_per_case))\n",
    "    \n",
    "    print('Tag Distribution')\n",
    "    dist = Counter(y)\n",
    "    print(dist)\n",
    "    \n",
    "    print('Cross validation evaluation...')\n",
    "    #print('Scores (F1-MACRO):', np.mean(cross_val_score(clf, X, y, cv = 5, scoring = 'f1_macro')))\n",
    "    #print('Scores (F1-MICRO):', np.mean(cross_val_score(clf, X, y, cv = 5, scoring = 'f1_micro')))\n",
    "    #print('Scores (F1-WEIGHTED):', np.mean(cross_val_score(clf, X, y, cv = 5, scoring = 'f1_weighted')))\n",
    "    \n",
    "    y_pred = cross_val_predict(clf, X, y, cv=3)\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    print('Training final model...')\n",
    "    clf.fit(X, y)\n",
    "    return clf, vectorizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def extract_CN_features(match, case, pattern, context_length = 10, purpose = 'train'):\n",
    "    '''Given a match will return the features associated with the specific example\n",
    "    Extracts the examples by finding the damage annotation tags\n",
    "    in the form <damage type = \"TYPE\">$5000</damage>\n",
    "    \n",
    "    Arguments:\n",
    "    match (Match Object) - Match object with the type as group 1 and value as group 2 if purpose = train, otherwise match group 0 is the value\n",
    "    case (str) - The case data in string format\n",
    "    pattern (str, regex pattern) - The regex pattern being used to find damages.\n",
    "                                      Used to remove the tags in features using context around value.\n",
    "    [Optional] context_length (int) - The number of words to use around the value for context\n",
    "    [Optional] purpose (str) - Default is 'train', used to determine pattern type\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    features (dict) - Dictionary containing each feature for the current match\n",
    "    damage_type (str) or None - The type of damage associated with the value if purpose = 'train'\n",
    "    '''\n",
    "    features = dict()\n",
    "    if purpose == 'train':\n",
    "        damage_type = match.group(1).strip()\n",
    "        damage_value = match.group(2).strip()\n",
    "    else:\n",
    "        damage_type = None\n",
    "        damage_value = match.group(0).strip()\n",
    "        \n",
    "    start_idx = match.start()\n",
    "    end_idx = match.end()\n",
    "    \n",
    "    # Get 3 * Context Length on each side \n",
    "    # Used to get rid of damage tags within context around our match\n",
    "    # We want to avoid getting half a damage tag else it wont be removed\n",
    "    # So we get more than we need.\n",
    "    start_tokenized = ' '.join(case[:start_idx].split()[context_length*3:])\n",
    "    end_tokenized = ' '.join(case[end_idx:].split()[:context_length*3])\n",
    "\n",
    "    if purpose == 'train':\n",
    "        # Remove damage tags in context around match\n",
    "        start_matches = pattern.finditer(start_tokenized)\n",
    "        for s in start_matches:\n",
    "            start_tokenized = start_tokenized.replace(s.group(0), s.group(2))\n",
    "        end_matches = pattern.finditer(end_tokenized)\n",
    "        for e in end_matches:\n",
    "            end_tokenized = end_tokenized.replace(e.group(0), e.group(2))\n",
    "\n",
    "    # Reconstruct sentence\n",
    "    tokens = start_tokenized + \" \" + damage_value + \" \" + end_tokenized \n",
    "    value_start_idx = len(start_tokenized.split()) # Location of value in relation to sentence (token level)\n",
    "    if len(damage_value.split()) > 1: # Deals with problems like '2 million' (where value is multiple tokens)\n",
    "        value_end_idx = value_start_idx + len(damage_value.split()) - 1\n",
    "    else:\n",
    "        value_end_idx = value_start_idx\n",
    "    tokens = tokens.split()\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        new_tokens.append(wordnet_lemmatizer.lemmatize(token))\n",
    "        \n",
    "    tokens = new_tokens\n",
    "    \n",
    "    # Features: Context_before, Context_after, Context\n",
    "    start_boundary = value_start_idx - context_length if value_start_idx - context_length >= 0 else 0\n",
    "    end_boundary = value_end_idx + context_length + 1 if value_end_idx + context_length + 1 < len(tokens) else len(tokens)\n",
    "    \n",
    "    features_bow_b = dict(Counter(tokens[start_boundary : value_start_idx]))\n",
    "    features_bow_b = {k+'@Before': v for k, v in features_bow_b.items()}\n",
    "    \n",
    "    features_bow_a = dict(Counter(tokens[value_end_idx + 1 : end_boundary]))\n",
    "    features_bow_a = {k+'@After': v for k, v in features_bow_a.items()}\n",
    "    \n",
    "    features.update(features_bow_b)\n",
    "    features.update(features_bow_a)\n",
    "    features.update(Counter(tokens))\n",
    "    \n",
    "    features['contributory_negligence'] = True if 'contributory negligence' in case.lower() else False\n",
    "    \n",
    "    plaintiff_defendant_pattern = r'([A-Za-z|-|\\.]+(:? \\(.*\\))?)+ v\\. ([A-Za-z|-]+)+' # group 1 is plaintiff group 2 is defendant\n",
    "    if re.search(plaintiff_defendant_pattern, case.split('\\n')[0]):\n",
    "        plaitiff_defendant = re.search(plaintiff_defendant_pattern, case.split('\\n')[0]).groups() # tuple (plaintiff, defendant)\n",
    "    else:\n",
    "        plaitiff_defendant = ('Plaintiff', 'Defendant')\n",
    "    plaintiff_split = [word.lower() for word in plaitiff_defendant[0].split()]\n",
    "    defendant_split = [word.lower() for word in plaitiff_defendant[-1].split()]\n",
    "    plaintiff_entities = ['plaintiff'] + plaintiff_split\n",
    "    defendant_entities = ['defendant'] + defendant_split\n",
    "    \n",
    "    features['plaintiff_mentioned'] = True if any(item in plaintiff_entities for item in tokens) else False\n",
    "    \n",
    "    features['defendant_mentioned'] = True if any(item in defendant_entities for item in tokens) else False\n",
    "    \n",
    "#     features['context_before'] = \" \".join(tokens[start_boundary : value_start_idx])\n",
    "#     features['context_after'] = \" \".join(tokens[value_end_idx + 1 : end_boundary])\n",
    "#     features['context'] = \" \".join(tokens[start_boundary : end_boundary])\n",
    "#     context = \" \".join(tokens[start_boundary : end_boundary])\n",
    "    features['value'] = damage_value\n",
    "#     #features['float'] = clean_money_amount([damage_value.strip('$')])\n",
    "    features['start_idx_ratio'] = match.start()/len(case)\n",
    "#     #features['greater_than_1000'] = features['float'] > 1000\n",
    "    \n",
    "#     features['#'] = True if '#' in features['context'] else False\n",
    "#     features['%'] = True if '%' in features['context'] else False\n",
    "#     features['$'] = True if '$' in features['context'] else False\n",
    "    \n",
    "\n",
    "    \n",
    "#     #del features['value']\n",
    "#     del features['context']\n",
    "#     del features['context_before']\n",
    "#     del features['context_after']\n",
    "    \n",
    "    if purpose == 'train':\n",
    "        return features, damage_type\n",
    "    else:\n",
    "        return features, damage_value\n",
    "\n",
    "def extract_features(match, case, pattern, context_length = 3, purpose = 'train'):\n",
    "    '''Given a match will return the features associated with the specific example\n",
    "    Extracts the examples by finding the damage annotation tags\n",
    "    in the form <damage type = \"TYPE\">$5000</damage>\n",
    "    \n",
    "    Arguments:\n",
    "    match (Match Object) - Match object with the type as group 1 and value as group 2 if purpose = train, otherwise match group 0 is the value\n",
    "    case (str) - The case data in string format\n",
    "    pattern (str, regex pattern) - The regex pattern being used to find damages.\n",
    "                                      Used to remove the tags in features using context around value.\n",
    "    [Optional] context_length (int) - The number of words to use around the value for context\n",
    "    [Optional] purpose (str) - Default is 'train', used to determine pattern type\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    features (dict) - Dictionary containing each feature for the current match\n",
    "    damage_type (str) or None - The type of damage associated with the value if purpose = 'train'\n",
    "    '''\n",
    "    features = dict()\n",
    "    if purpose == 'train':\n",
    "        damage_type = match.group(1)\n",
    "        damage_value = match.group(2)\n",
    "    else:\n",
    "        damage_type = None\n",
    "        damage_value = match.group(0)\n",
    "        \n",
    "    start_idx = match.start()\n",
    "    end_idx = match.end()\n",
    "    \n",
    "    # Get 3 * Context Length on each side \n",
    "    # Used to get rid of damage tags within context around our match\n",
    "    # We want to avoid getting half a damage tag else it wont be removed\n",
    "    # So we get more than we need.\n",
    "    start_tokenized = ' '.join(case[:start_idx].split()[context_length*3:])\n",
    "    end_tokenized = ' '.join(case[end_idx:].split()[:context_length*3])\n",
    "\n",
    "    if purpose == 'train':\n",
    "        # Remove damage tags in context around match\n",
    "        start_matches = pattern.finditer(start_tokenized)\n",
    "        for s in start_matches:\n",
    "            start_tokenized = start_tokenized.replace(s.group(0), s.group(2))\n",
    "        end_matches = pattern.finditer(end_tokenized)\n",
    "        for e in end_matches:\n",
    "            end_tokenized = end_tokenized.replace(e.group(0), e.group(2))\n",
    "\n",
    "    # Reconstruct sentence\n",
    "    tokens = start_tokenized + \" \" + damage_value + \" \" + end_tokenized \n",
    "    value_start_idx = len(start_tokenized.split()) # Location of value in relation to sentence (token level)\n",
    "    if len(damage_value.split()) > 1: # Deals with problems like '2 million' (where value is multiple tokens)\n",
    "        value_end_idx = value_start_idx + len(damage_value.split()) - 1\n",
    "    else:\n",
    "        value_end_idx = value_start_idx\n",
    "    tokens = tokens.split()\n",
    "    \n",
    "    # Features: Context_before, Context_after, Context\n",
    "    start_boundary = value_start_idx - context_length if value_start_idx - context_length >= 0 else 0\n",
    "    end_boundary = value_end_idx + context_length + 1 if value_end_idx + context_length + 1 < len(tokens) else len(tokens)\n",
    "    \n",
    "#     features_bow_b = dict(Counter(tokens[start_boundary : value_start_idx]))\n",
    "#     features_bow_b = {k+'@Before': v for k, v in features_bow_b.items()}\n",
    "    \n",
    "#     features_bow_a = dict(Counter(tokens[value_end_idx + 1 : end_boundary]))\n",
    "#     features_bow_a = {k+'@After': v for k, v in features_bow_a.items()}\n",
    "    \n",
    "#     features.update(features_bow_b)\n",
    "#     features.update(features_bow_a)\n",
    "    \n",
    "    \n",
    "#     features['context_before'] = \" \".join(tokens[start_boundary : value_start_idx])\n",
    "#     features['context_after'] = \" \".join(tokens[value_end_idx + 1 : end_boundary])\n",
    "#     features['context'] = \" \".join(tokens[start_boundary : end_boundary])\n",
    "    context = \" \".join(tokens[start_boundary : end_boundary])\n",
    "#     features['value'] = damage_value\n",
    "#     #features['float'] = clean_money_amount([damage_value.strip('$')])\n",
    "#     features['start_idx_ratio'] = match.start()/len(case)\n",
    "#     #features['greater_than_1000'] = features['float'] > 1000\n",
    "    \n",
    "#     features['#'] = True if '#' in features['context'] else False\n",
    "#     features['%'] = True if '%' in features['context'] else False\n",
    "#     features['$'] = True if '$' in features['context'] else False\n",
    "    \n",
    "\n",
    "    \n",
    "#     #del features['value']\n",
    "#     del features['context']\n",
    "#     del features['context_before']\n",
    "#     del features['context_after']\n",
    "    \n",
    "    damages_keywords = dict()\n",
    "    damages_keywords['non-pecuniary'] = ['non pecuniary', 'non-pecuniary', 'pain', 'suffering', 'enjoyment']\n",
    "    damages_keywords['special'] = ['special damages', 'housekeeping', 'homemaking', 'in trust', 'in-trust' 'bill', 'receipt', 'costs']\n",
    "    damages_keywords['future care'] = ['future care', 'care', 'massage', 'pysio', 'therapy', 'medical', 'costs']\n",
    "    damages_keywords['wage loss'] = ['wage', 'loss', 'income', 'work', 'employment', 'inability', 'earning capacity', 'earning', 'ability']\n",
    "    damages_keywords['total'] = ['total', 'damages are', 'assessed', 'sum', 'awarded']\n",
    "    damages_keywords['aggravated'] = ['aggravated']\n",
    "    damages_keywords['punitive'] = ['punitive']\n",
    "    damages_keywords['general'] = ['general']\n",
    "    damages_keywords['reduction'] = ['reduc', 'less', 'discounted', 'recover', '%']\n",
    "    \n",
    "    features['value'] = damage_value\n",
    "    features['float'] = clean_money_amount([damage_value.strip('$')])\n",
    "    features['start_idx_ratio'] = match.start()/len(case)\n",
    "#     features['greater_than_1000'] = features['float'] > 1000\n",
    "    # Feautures: Lexicon per damage type\n",
    "    features['punitive lexicon'] = True if any(word in context for word in damages_keywords['punitive']) else False\n",
    "    features['non-pecuniary lexicon'] = True if any(word in context for word in damages_keywords['non-pecuniary']) else False\n",
    "    features['special lexicon'] = True if any(word in context for word in damages_keywords['special']) else False\n",
    "    features['general lexicon'] = True if any(word in context for word in damages_keywords['general']) else False\n",
    "    features['aggravated lexicon'] = True if any(word in context for word in damages_keywords['aggravated']) else False\n",
    "    features['future wage loss lexicon'] = True if ('future' in context or 'loss' in context) and any(word in context for word in damages_keywords['wage loss']) else False\n",
    "    features['past wage loss lexicon'] = True if ('past' in context or 'previous' in context) and any(word in context for word in damages_keywords['wage loss']) else False\n",
    "    features['total lexicon'] = True if any(word in context for word in damages_keywords['total']) else False\n",
    "    features['reduction lexicon'] = True if any(word in context for word in damages_keywords['reduction']) else False\n",
    "    # replace non-word characters and numbers from context to help BOW\n",
    "    before = re.sub(r'[\\W0-9]', ' ', \" \".join(tokens[start_boundary : value_start_idx])).split()\n",
    "    after = re.sub(r'[\\W0-9]', ' ', \" \".join(tokens[value_end_idx + 1 : end_boundary])).split()\n",
    "    context = re.sub(r'[\\W0-9]', ' ', context)\n",
    "    features_bow_b = dict(Counter(before))\n",
    "    features_bow_b = {k+'@Before': v for k, v in features_bow_b.items()}\n",
    "    features_bow_a = dict(Counter(after))\n",
    "    features_bow_a = {k+'@After': v for k, v in features_bow_a.items()}\n",
    "    if len(before) > 0:\n",
    "        features['prev word'] = before[-1]\n",
    "    else:\n",
    "        features['prev word'] = ''\n",
    "#     if len(before) > 1:\n",
    "#         features['next bigram'] = \" \".join(before[-2:])\n",
    "#     else:\n",
    "#         features['next bigram'] = ''\n",
    "    if len(after) > 0:\n",
    "        features['next word'] = after[0]\n",
    "    else:\n",
    "        features['next word'] = ''\n",
    "\n",
    "    features.update(features_bow_b)\n",
    "    features.update(features_bow_a)\n",
    "    features.update(Counter(context.split()))\n",
    "    \n",
    "    if purpose == 'train':\n",
    "        return features, damage_type\n",
    "    else:\n",
    "        return features, damage_value\n",
    "\n",
    "def predict(case, clf, vectorizer):\n",
    "    '''Given a legal negligence case (str), a trained classifier, and a fit_transformed DictVectorizer(), \n",
    "    Return a list of tuples of (value, prediction, value_location), where value_location is the ratio of the \n",
    "    character start index \n",
    "    ----------------------\n",
    "    Arguments:\n",
    "    case: legal negligence case (str)\n",
    "    clf: trained classifier with .fit method\n",
    "    vecotrizer: fit_transformed vectorizer (sklean DictVectorizer())\n",
    "    ----------------------\n",
    "    Return: list of tuples or an empty list if no matches in the case\n",
    "    Example: \n",
    "    case = 'I award $5,000 in punitive damages.'\n",
    "    predict(case, clf, vectorizer)\n",
    "    > [($5,000, 'punitive', 0.023)]'''\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    value_extractor = re.compile('''\\$ ?[1-9]+[0-9|,|\\.]+''')\n",
    "    case_examples = []\n",
    "    value_locations = []\n",
    "    values = []\n",
    "\n",
    "    # lower case and remove stopwords\n",
    "    case = ' '.join([word for word in case.lower().split() if word not in stop_words])\n",
    "    matches = value_extractor.finditer(case) # Extract all <damage ...>$x</damage> tags used for training\n",
    "    for match in matches:\n",
    "        # extract features per match found\n",
    "        features, _ = extract_features(match, case, value_extractor, purpose = 'predict')\n",
    "        case_examples.append(features)\n",
    "        value_locations.append(features['start_idx_ratio'])\n",
    "        #values.append(clean_money_amount([features['value'].strip('$')]))\n",
    "        values.append(clean_money_amount([_.strip('$')]))\n",
    "        \n",
    "    # if money values found in the case, predict type\n",
    "    if len(case_examples) > 0:\n",
    "        X_test = vectorizer.transform(case_examples)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_prob = clf.predict_proba(X_test)\n",
    "        return list(zip(values, y_pred, value_locations, y_prob))\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def assign_classification_damages(predictions, min_score = 0.7):\n",
    "    '''Helper function for rule based BCJ\n",
    "    Handles assigning predictions into final damage amounts\n",
    "    \n",
    "    Arguments:\n",
    "    predictions (tuple returned from predict function)\n",
    "    min_score (float) - If a prediction appears before this point in the case it is discarded\n",
    "    \n",
    "    Returns:\n",
    "    damages (defaultdict(float)) - Damages with values filled in based on predictions\n",
    "    '''\n",
    "    \n",
    "    damages = defaultdict(float)\n",
    "    temporary_damages = defaultdict(list)\n",
    "    for value, prediction_type, ratio, predict_proba in predictions:\n",
    "        if ratio < min_score:\n",
    "            continue\n",
    "        \n",
    "        #print(value, prediction_type, ratio)\n",
    "        if prediction_type == 'total':\n",
    "            #print(sum(predict_proba), max(predict_proba))\n",
    "            if max(predict_proba) > 0.85:\n",
    "                temporary_damages[prediction_type].append(value)\n",
    "        else:\n",
    "            temporary_damages[prediction_type].append(value)\n",
    "\n",
    "    # Currently not dealing with \"reduction\" or \"total after\" (or total - manually adding)\n",
    "    damages['Future Care'] = temporary_damages['future care'][-1] if len(temporary_damages['future care']) != 0 \\\n",
    "                             else sum(temporary_damages['sub-future care'])\n",
    "        \n",
    "    damages['Future Wage Loss'] = temporary_damages['future wage loss'][-1] if len(temporary_damages['future wage loss']) != 0 \\\n",
    "                                  else sum(temporary_damages['sub-future wage loss'])\n",
    "        \n",
    "    damages['General'] = temporary_damages['general'][-1] if len(temporary_damages['general']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-general'])\n",
    "    \n",
    "    damages['In Trust'] = temporary_damages['in trust'][-1] if len(temporary_damages['in trust']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-in trust'])\n",
    "    \n",
    "    damages['Non Pecuniary'] = temporary_damages['non pecuniary'][-1] if len(temporary_damages['non pecuniary']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-non pecuniary'])\n",
    "    \n",
    "    damages['Past Wage Loss'] = temporary_damages['past wage loss'][-1] if len(temporary_damages['past wage loss']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-past wage loss'])\n",
    "    \n",
    "    damages['Punitive'] = temporary_damages['punitive'][-1] if len(temporary_damages['punitive']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-punitive'])\n",
    "\n",
    "    damages['Special'] = temporary_damages['special'][-1] if len(temporary_damages['special']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-special'])\n",
    "    \n",
    "    damages['Aggravated'] = temporary_damages['aggravated'][-1] if len(temporary_damages['aggravated']) != 0 \\\n",
    "                         else sum(temporary_damages['sub-saggravated'])\n",
    "    \n",
    "    damages['Total'] = temporary_damages['total'][-1] if len(temporary_damages['total']) != 0 \\\n",
    "                         else None\n",
    "    \n",
    "    damages['General'] += damages['Future Wage Loss']\n",
    "    damages['Special'] += damages['Past Wage Loss'] + damages['In Trust']\n",
    "\n",
    "    damages['Pecuniary Total'] = damages['Special'] + damages['General'] + damages['Future Care']\n",
    "    if damages['Total'] is None:\n",
    "        damages['Total'] = damages['Pecuniary Total'] + damages['Non Pecuniary'] + damages['Aggravated']\n",
    "    \n",
    "    columns = ['Total', 'Pecuniary Total', 'Non Pecuniary', 'Special', 'General', 'Punitive', 'Aggravated', 'Future Care']\n",
    "    for c in columns:\n",
    "        damages[c] = None if damages[c] == 0 else damages[c]\n",
    "    \n",
    "    return damages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_convert_cases_to_DF(cases):\n",
    "    '''Given a list of parsed cases returns a dataframe'''\n",
    "\n",
    "    lists = defaultdict(list)    \n",
    "    for case in cases:\n",
    "        lists['Case Number'].append(case['case_number'])\n",
    "        lists['Case Name'].append(case['case_title'])\n",
    "        lists['Year'].append(case['year'])\n",
    "        lists['Total Damage'].append(case['damages']['Total'] if case['damages'] != None else None)\n",
    "        lists['Total Pecuniary'].append(case['damages']['Pecuniary Total'] if case['damages'] != None else None)\n",
    "        lists['Non Pecuniary'].append(case['damages']['Non Pecuniary'] if case['damages'] != None else None)\n",
    "        lists['General'].append(case['damages']['General'] if case['damages'] != None else None)\n",
    "        lists['Special'].append(case['damages']['Special'] if case['damages'] != None else None)\n",
    "        lists['Punitive'].append(case['damages']['Punitive'] if case['damages'] != None else None)\n",
    "        lists['Aggravated'].append(case['damages']['Aggravated'] if case['damages'] != None else None)\n",
    "        lists['Future Care'].append(case['damages']['Future Care'] if case['damages'] != None else None)\n",
    "        lists['Judge Name'].append(case['judge'])\n",
    "        lists['Decision Length'].append(case['decision_length'])\n",
    "        lists['Multiple defendants?'].append(case['multiple_defendants'])\n",
    "        lists['Plaintiff Wins?'].append(case['plaintiff_wins'])\n",
    "        lists['Contributory Negligence Raised'].append(case['contributory_negligence_raised'])\n",
    "        lists['Written Decision?'].append(case['written_decision'])\n",
    "        lists['Registry'].append(case['registry'])\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    for key in lists.keys():\n",
    "        df[key] = lists[key]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evaluate(dev_data, gold_data, subset=None):\n",
    "    '''Evaluates the results against a gold standard set\n",
    "    \n",
    "    Arguments:\n",
    "    dev_data (dataframe) - Dataframe containing results from rule based parse BCJ\n",
    "    gold_data (dataframe) - Dataframe containing manually annotated data\n",
    "    (Optional) subset (list/string) - Specific columns to evaluate\n",
    "\n",
    "    '''\n",
    "    \n",
    "    print('#### Evaluation ####')\n",
    "    \n",
    "    # Use case name as 'primary key'\n",
    "    dev_case_names = list(dev_data['Case Name'])\n",
    "    gold_case_names = list(gold_data['Case Name'])\n",
    "    \n",
    "    # Filter data to only use overlapping items\n",
    "    gold_data = gold_data[gold_data['Case Name'].isin(dev_case_names)]    \n",
    "    dev_data = dev_data[dev_data['Case Name'].isin(gold_case_names)]\n",
    "    \n",
    "    # Mapping from our variable names to Lachlan's column names\n",
    "    column_mapping = {'Decision Length': 'Decision Length: paragraphs)',\n",
    "                      'Total Damage': '$ Damages total before contributory negligence',\n",
    "                      'Non Pecuniary': '$ Non-Pecuniary Damages', \n",
    "                      'Total Pecuniary': '$ Pecuniary Damages Total',\n",
    "                      'Special': '$ Special damages Pecuniary (ie. any expenses already incurred)',\n",
    "                      'Future Care': 'Future Care Costs (General Damages)',\n",
    "                      'General': '$ General Damages',\n",
    "                      'Punitive': '$ Punitive Damages',\n",
    "                      'Aggravated': '$Aggravated Damages',\n",
    "                      'Contributory Negligence Raised': 'Contributory Negligence Raised?'}\n",
    "                      # ADD ADDITIONAL COLUMNS HERE\n",
    "    \n",
    "    dev_data.rename(columns = column_mapping, inplace = True)\n",
    "     \n",
    "    if subset is None: # Use all columns if no subset specified\n",
    "        subset = dev_data.columns\n",
    "        \n",
    "    \n",
    "        \n",
    "    for column in dev_data.columns:\n",
    "        if column in gold_data.columns:\n",
    "            if column in subset:\n",
    "                # Stores how off our answers are\n",
    "                errors = []\n",
    "                \n",
    "                empty_correct = 0\n",
    "                non_empty_correct = 0\n",
    "                total_empty = 0\n",
    "                total_non_empty = 0\n",
    "                for case_name in list(dev_data['Case Name']):\n",
    "                    dev_value = list(dev_data[dev_data['Case Name'] == case_name][column])[0]\n",
    "                    gold_value = list(gold_data[gold_data['Case Name'] == case_name][column])[0]\n",
    "\n",
    "                    # Convert string to float if possible\n",
    "                    try:\n",
    "                        gold_value = float(gold_value)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        dev_value = float(dev_value)\n",
    "                    except:\n",
    "                        pass\n",
    "                    # Set values to 'None' if they're a NaN float value\n",
    "                    dev_value = None if isinstance(dev_value, float) and math.isnan(dev_value) else dev_value\n",
    "                    gold_value = None if isinstance(gold_value, float) and math.isnan(gold_value) else gold_value\n",
    "                    # Lowercase values if they're a string\n",
    "                    dev_value = dev_value.lower().strip() if isinstance(dev_value, str) else dev_value\n",
    "                    gold_value = gold_value.lower().strip() if isinstance(gold_value, str) else gold_value\n",
    "\n",
    "                    if gold_value is None:\n",
    "                        total_empty += 1\n",
    "                        if dev_value is None:\n",
    "                            empty_correct += 1\n",
    "                        elif isinstance(dev_value, float):\n",
    "                            errors.append(dev_value)\n",
    "                    else:\n",
    "                        total_non_empty += 1\n",
    "                        if isinstance(dev_value, float) and isinstance(gold_value, float):\n",
    "                            if math.isclose(dev_value, gold_value, abs_tol=1): # Tolerance within 1\n",
    "                                non_empty_correct += 1\n",
    "                            else:\n",
    "                                errors.append(abs(gold_value-dev_value))\n",
    "                        elif dev_value == gold_value:\n",
    "                            non_empty_correct += 1\n",
    "                        \n",
    "                print('-------')\n",
    "                print('COLUMN:', column)\n",
    "                if total_empty != 0:\n",
    "                    print('Empty field accuracy:', empty_correct / total_empty * 100, '%', empty_correct, '/', total_empty)\n",
    "                if total_non_empty != 0:\n",
    "                    print('Filled field accuracy:', non_empty_correct / total_non_empty * 100, '%', non_empty_correct, '/', total_non_empty)\n",
    "                \n",
    "                if len(errors) > 0:\n",
    "                    print('Average $ Error: $' + str(np.mean(errors)))\n",
    "                print('Overall accuracy:', (empty_correct+non_empty_correct) / (total_non_empty+total_empty) * 100, '%', (empty_correct+non_empty_correct), '/', (total_non_empty+total_empty))\n",
    "    \n",
    "    #for testing:\n",
    "    #return dev_data, gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    }
   ],
   "source": [
    "a = ['test', 'that']\n",
    "\n",
    "b = ['my', 'tokens', 'this']\n",
    "\n",
    "if any(item in b for item in a):\n",
    "    print('t')\n",
    "else:\n",
    "    print('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../../data/Lexis Cases txt/'\n",
    "file_prefix = 'P'\n",
    "file_suffix = '.txt'\n",
    "file_identifiers = range(1, 86) # Range from 1 to 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classifier Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didnt find any tags in Dr. Andrew Hokhold Inc. v. Wells (c.o.b. Spall Machine & Welding), [2005] B.C.J. No. 255\n",
      "Didnt find any tags in Cowie v. Draper, [2010] B.C.J. No. 910000005 %\n",
      "Didnt find any tags in Bajwa v. Deol, [2018] I.L.R. para. G-2792\n",
      "Didnt find any tags in Jackson v. Fisheries and Oceans Canada, [2006] B.C.J. No. 2654\n",
      "Didnt find any tags in Kappell v. Brown, [2012] B.C.J. No. 139\n",
      "Didnt find any tags in Austin v. Joaquin, [2007] B.C.J. No. 189499 %\n",
      "Didnt find any tags in Los Angeles Salad Co. v. Canadian Food Inspection Agency, [2009] B.C.J. No. 161\n",
      "Didnt find any tags in Fichtner v. Johnston Meier Insurance Services Ltd., [2001] B.C.J. No. 1666\n",
      "Didnt find any tags in Mclaren v. Rice, [2009] B.C.J. No. 210800001 %\n",
      "Didnt find any tags in Gray v. Ellis, [2007] I.L.R. para. M-2118999 %\n",
      "Didnt find any tags in Morrow v. Outerbridge, 2009 CHFL para. 15,554%\n",
      "Didnt find any tags in Paniccia v. Eckert, [2012] B.C.J. No. 1997\n",
      "Didnt find any tags in Johal v. Conron, [2013] B.C.J. No. 231800003 %\n",
      "Didnt find any tags in Ho v. Lau, [2012] B.C.J. No. 2561\n",
      "Didnt find any tags in Rackstraw (Litigation guardian of) v. Robertson, [2011] B.C.J. No. 1354\n",
      "Didnt find any tags in Ahlwat v. Green, [2014] B.C.J. No. 245200004 %\n",
      "Didnt find any tags in Mardones v. Toyota Credit Canada Inc., [2008] B.C.J. No. 1217\n",
      "Didnt find any tags in McGavin v. Talbot, [2017] B.C.J. No. 2439998 %\n",
      "Didnt find any tags in C.H. v. British Columbia, [2003] B.C.J. No. 1706\n",
      "Didnt find any tags in Wettlaufer v. Air Transat A.T. Inc., [2013] B.C.J. No. 1531\n",
      "Didnt find any tags in Stovel v. Paul, [2013] B.C.J. No. 33\n",
      "Didnt find any tags in Arbutus Bay Estates Ltd. v. Canada (Attorney General), [2016] B.C.J. No. 2351\n",
      "Didnt find any tags in Myatt v. Holicza, [2000] B.C.J. No. 1610\n",
      "Didnt find any tags in P.B. v. R.V.E., [2007] B.C.J. No. 2305000004 %\n",
      "Didnt find any tags in Uppal v. Rawlins, [2010] B.C.J. No. 16999996 %\n",
      "Didnt find any tags in Ahmadi v. West, [2014] B.C.J. No. 2680\n",
      "Didnt find any tags in Fiessel v. Fiessel, [2006] B.C.J. No. 168606 %\n",
      "Didnt find any tags in Bouvier v. Behrend, [2014] B.C.J. No. 136296 %\n",
      "Didnt find any tags in GE Capital Canada Equipment Financing Inc. v. Bank of Montreal, [2003] B.C.J. No. 1791\n",
      "Didnt find any tags in Mennonite Church British Columbia v. Sur-Del Roofing Ltd., [2010] B.C.J. No. 297\n",
      "Didnt find any tags in Neff v. Patry, [2008] B.C.J. No. 2099999999 %\n",
      "Didnt find any tags in Rycroft v. Rego, [2017] B.C.J. No. 447\n",
      "Didnt find any tags in Chamberlain v. Pro Star Mechanical Technologies Ltd., [2014] B.C.J. No. 2669\n",
      "Didnt find any tags in Cox v. Bounthavilay, [2007] B.C.J. No. 1776 %\n",
      "Didnt find any tags in Mainardi v. Shannon, [2005] B.C.J. No. 1033 %\n",
      "Reading training data and extracting features... 99.2 %\n",
      "Vectorizing...\n",
      "Tag Distribution\n",
      "Counter({'other': 695, 'cnd': 93, 'cnp': 83, 'sub-cnd': 6})\n",
      "Cross validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rapindergill/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cnd       0.17      0.42      0.25        93\n",
      "         cnp       0.12      0.22      0.15        83\n",
      "       other       0.89      0.63      0.74       695\n",
      "     sub-cnd       0.20      0.33      0.25         6\n",
      "\n",
      "    accuracy                           0.57       877\n",
      "   macro avg       0.35      0.40      0.35       877\n",
      "weighted avg       0.74      0.57      0.63       877\n",
      "\n",
      "Training final model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rapindergill/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = train_CN_classifier('../../data/annotations/all_annotations_CN.txt', clf = LogisticRegression(solver = 'newton-cg', C = 1, penalty = 'l2', class_weight = 'balanced'))\n",
    "#model, vectorizer = train_classifier('../../data/annotations/all_annotations.txt', clf = xgb.XGBClassifier())\n",
    "#model, vectorizer = train_classifier('../../data/annotations/all_annotations.txt', clf = RandomForestClassifier())\n",
    "\n",
    "#model, vectorizer = train_CN_classifier('../../data/annotations/all_annotations_CN.txt', clf = RandomForestClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: cnd\n",
      "Feature: value=25 per cent\n",
      "Feature: plaintiff@Before\n",
      "Feature: 75@Before\n",
      "Feature: 15@After\n",
      "Feature: value=70%\n",
      "------------\n",
      "Class: cnp\n",
      "Feature: value=75 per cent\n",
      "Feature: 25@After\n",
      "Feature: 85@Before\n",
      "Feature: 20%@After\n",
      "Feature: value=80%\n",
      "------------\n",
      "Class: other\n",
      "Feature: value=100%\n",
      "Feature: v.@Before\n",
      "Feature: -\n",
      "Feature: found@After\n",
      "Feature: jury@After\n",
      "------------\n",
      "Class: sub-cnd\n",
      "Feature: value=25%\n",
      "Feature: 50%@After\n",
      "Feature: accident@Before\n",
      "Feature: klock\n",
      "Feature: responsible@After\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "def get_top_features(n, model, vectorizer):\n",
    "    for i, feature in enumerate(model.classes_):\n",
    "        feature_weights = model.coef_[i]\n",
    "        idx = (-feature_weights).argsort()[:n]\n",
    "        print('Class:', feature)\n",
    "        for i in idx:\n",
    "            print('Feature:', vectorizer.feature_names_[i])\n",
    "        print('------------')\n",
    "        \n",
    "get_top_features(5, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classifier Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Processing ../../data/Lexis Cases txt/P85.txt ##\r"
     ]
    }
   ],
   "source": [
    "clf_results = []\n",
    "for file_number in file_identifiers:\n",
    "    print('## Processing ' + path_to_data + file_prefix + str(file_number) + file_suffix + ' ##', end='\\r')\n",
    "    clf_results.extend(rule_based_parse_BCJ(path_to_data + file_prefix + str(file_number) + file_suffix, model, vectorizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classifier Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Evaluation ####\n",
      "-------\n",
      "COLUMN: Case Number\n",
      "Filled field accuracy: 0.0 % 0 / 30\n",
      "Overall accuracy: 0.0 % 0 / 30\n",
      "-------\n",
      "COLUMN: Case Name\n",
      "Filled field accuracy: 100.0 % 30 / 30\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: $ Damages total before contributory negligence\n",
      "Empty field accuracy: 100.0 % 2 / 2\n",
      "Filled field accuracy: 82.14285714285714 % 23 / 28\n",
      "Average $ Error: $187916.0275\n",
      "Overall accuracy: 83.33333333333334 % 25 / 30\n",
      "-------\n",
      "COLUMN: $ Pecuniary Damages Total\n",
      "Empty field accuracy: 100.0 % 1 / 1\n",
      "Filled field accuracy: 58.620689655172406 % 17 / 29\n",
      "Average $ Error: $142672.01571428572\n",
      "Overall accuracy: 60.0 % 18 / 30\n",
      "-------\n",
      "COLUMN: $ Non-Pecuniary Damages\n",
      "Empty field accuracy: 100.0 % 11 / 11\n",
      "Filled field accuracy: 100.0 % 19 / 19\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: $ General Damages\n",
      "Empty field accuracy: 100.0 % 13 / 13\n",
      "Filled field accuracy: 76.47058823529412 % 13 / 17\n",
      "Average $ Error: $63750.0\n",
      "Overall accuracy: 86.66666666666667 % 26 / 30\n",
      "-------\n",
      "COLUMN: $ Special damages Pecuniary (ie. any expenses already incurred)\n",
      "Empty field accuracy: 87.5 % 7 / 8\n",
      "Filled field accuracy: 81.81818181818183 % 18 / 22\n",
      "Average $ Error: $93112.822\n",
      "Overall accuracy: 83.33333333333334 % 25 / 30\n",
      "-------\n",
      "COLUMN: $ Punitive Damages\n",
      "Empty field accuracy: 100.0 % 30 / 30\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: $Aggravated Damages\n",
      "Empty field accuracy: 100.0 % 30 / 30\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: Future Care Costs (General Damages)\n",
      "Empty field accuracy: 100.0 % 17 / 17\n",
      "Filled field accuracy: 100.0 % 13 / 13\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: Judge Name\n",
      "Filled field accuracy: 0.0 % 0 / 30\n",
      "Overall accuracy: 0.0 % 0 / 30\n",
      "-------\n",
      "COLUMN: Decision Length: paragraphs)\n",
      "Filled field accuracy: 100.0 % 30 / 30\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: Multiple defendants?\n",
      "Filled field accuracy: 96.66666666666667 % 29 / 30\n",
      "Overall accuracy: 96.66666666666667 % 29 / 30\n",
      "-------\n",
      "COLUMN: Plaintiff Wins?\n",
      "Filled field accuracy: 93.33333333333333 % 28 / 30\n",
      "Overall accuracy: 93.33333333333333 % 28 / 30\n",
      "-------\n",
      "COLUMN: Contributory Negligence Raised?\n",
      "Filled field accuracy: 86.66666666666667 % 26 / 30\n",
      "Overall accuracy: 86.66666666666667 % 26 / 30\n",
      "-------\n",
      "COLUMN: Written Decision?\n",
      "Filled field accuracy: 100.0 % 30 / 30\n",
      "Overall accuracy: 100.0 % 30 / 30\n",
      "-------\n",
      "COLUMN: Registry\n",
      "Filled field accuracy: 100.0 % 30 / 30\n",
      "Overall accuracy: 100.0 % 30 / 30\n"
     ]
    }
   ],
   "source": [
    "gold_df = pd.read_csv('../../data/gold_annotations.csv', skiprows = lambda x: x in range(1, 100))\n",
    "gold_df.dropna(how = 'all', inplace=True) \n",
    "\n",
    "dev_df = rule_based_convert_cases_to_DF(clf_results)\n",
    "evaluate(dev_df, gold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rule Based Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Processing ../../data/Lexis Cases txt/P85.txt ##\r"
     ]
    }
   ],
   "source": [
    "rb_results = []\n",
    "for file_number in file_identifiers:\n",
    "    print('## Processing ' + path_to_data + file_prefix + str(file_number) + file_suffix + ' ##', end='\\r')\n",
    "    rb_results.extend(rule_based_parse_BCJ(path_to_data + file_prefix + str(file_number) + file_suffix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rule Based Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Evaluation ####\n",
      "-------\n",
      "COLUMN: $ Damages total before contributory negligence\n",
      "Empty field accuracy: 83.33333333333334 % 5 / 6\n",
      "Filled field accuracy: 37.5 % 33 / 88\n",
      "Average $ Error: $215016.4290909091\n",
      "Overall accuracy: 40.42553191489361 % 38 / 94\n"
     ]
    }
   ],
   "source": [
    "# Skip Lachlan's annotations. I looked at these when developing the rules for the system\n",
    "# Want our evaluation to be un-biased\n",
    "gold_df = pd.read_csv('../../data/gold_annotations.csv', skiprows = lambda x: x in range(1, 31))\n",
    "gold_df.dropna(how = 'all', inplace=True) \n",
    "\n",
    "dev_df = rule_based_convert_cases_to_DF(rb_results)\n",
    "evaluate(dev_df, gold_df, subset = ['$ Damages total before contributory negligence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total Damage</th>\n",
       "      <th>Total Pecuniary</th>\n",
       "      <th>Non Pecuniary</th>\n",
       "      <th>General</th>\n",
       "      <th>Special</th>\n",
       "      <th>Punitive</th>\n",
       "      <th>Aggravated</th>\n",
       "      <th>Future Care</th>\n",
       "      <th>Judge Name</th>\n",
       "      <th>Decision Length</th>\n",
       "      <th>Multiple defendants?</th>\n",
       "      <th>Plaintiff Wins?</th>\n",
       "      <th>Contributory Negligence Raised</th>\n",
       "      <th>Written Decision?</th>\n",
       "      <th>Registry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 of 1</td>\n",
       "      <td>Mawani v. Pitcairn, [2012] B.C.J. No. 1819</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.F. Kelleher J.</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 of 1</td>\n",
       "      <td>Ediger (Guardian ad litem of) v. Johnston, [20...</td>\n",
       "      <td>2009</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H.J. Holmes J.</td>\n",
       "      <td>350</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 of 1</td>\n",
       "      <td>Furness v. Guest, [2010] B.C.J. No. 1388</td>\n",
       "      <td>2010</td>\n",
       "      <td>42041.40</td>\n",
       "      <td>42041.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42041.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D.A. Halfyard J.</td>\n",
       "      <td>97</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Nanaimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 of 1</td>\n",
       "      <td>Howell v. Machi, [2017] B.C.J. No. 2016</td>\n",
       "      <td>2017</td>\n",
       "      <td>2178781.77</td>\n",
       "      <td>2178781.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050000.0</td>\n",
       "      <td>28781.77</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. MacNaughton</td>\n",
       "      <td>525</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 of 1</td>\n",
       "      <td>Morrow v. Outerbridge, [2009] B.C.J. No. 640</td>\n",
       "      <td>2009</td>\n",
       "      <td>800000.00</td>\n",
       "      <td>800000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E.A. Bennett J.</td>\n",
       "      <td>311</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>4235 of 85</td>\n",
       "      <td>Willson v. Angela Gibson Law Corp., [2008] B.C...</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard: August 29 (written submissions of the</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>4236 of 85</td>\n",
       "      <td>Wong v. British Columbia (Securities Commissio...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F.W. Cole J.</td>\n",
       "      <td>40</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>4237 of 85</td>\n",
       "      <td>Wood v. Langley (Township), [2015] B.C.J. No. ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J.W. Williams J.</td>\n",
       "      <td>110</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>4238 of 85</td>\n",
       "      <td>Yang v. Fourso, [2017] B.C.J. No. 2859</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master R. McDiarmid (In Chambers)</td>\n",
       "      <td>27</td>\n",
       "      <td>Y</td>\n",
       "      <td>OpenCase</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>4239 of 85</td>\n",
       "      <td>Yazdi Integrated Health Group Ltd. v. Unihealt...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N.H. Smith J.</td>\n",
       "      <td>38</td>\n",
       "      <td>Y</td>\n",
       "      <td>OpenCase</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Vancouver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3852 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number                                          Case Name  Year  \\\n",
       "0         1 of 1         Mawani v. Pitcairn, [2012] B.C.J. No. 1819  2012   \n",
       "1         2 of 1  Ediger (Guardian ad litem of) v. Johnston, [20...  2009   \n",
       "2         3 of 1           Furness v. Guest, [2010] B.C.J. No. 1388  2010   \n",
       "3         4 of 1            Howell v. Machi, [2017] B.C.J. No. 2016  2017   \n",
       "4         5 of 1       Morrow v. Outerbridge, [2009] B.C.J. No. 640  2009   \n",
       "...          ...                                                ...   ...   \n",
       "3847  4235 of 85  Willson v. Angela Gibson Law Corp., [2008] B.C...  2008   \n",
       "3848  4236 of 85  Wong v. British Columbia (Securities Commissio...  2011   \n",
       "3849  4237 of 85  Wood v. Langley (Township), [2015] B.C.J. No. ...  2015   \n",
       "3850  4238 of 85             Yang v. Fourso, [2017] B.C.J. No. 2859  2017   \n",
       "3851  4239 of 85  Yazdi Integrated Health Group Ltd. v. Unihealt...  2015   \n",
       "\n",
       "      Total Damage  Total Pecuniary  Non Pecuniary    General   Special  \\\n",
       "0              NaN              NaN            NaN        NaN       NaN   \n",
       "1         20000.00              NaN            NaN    20000.0       NaN   \n",
       "2         42041.40         42041.40            NaN        NaN  42041.40   \n",
       "3       2178781.77       2178781.77            NaN  2050000.0  28781.77   \n",
       "4        800000.00        800000.00            NaN        NaN       NaN   \n",
       "...            ...              ...            ...        ...       ...   \n",
       "3847           NaN              NaN            NaN        NaN       NaN   \n",
       "3848           NaN              NaN            NaN        NaN       NaN   \n",
       "3849           NaN              NaN            NaN        NaN       NaN   \n",
       "3850           NaN              NaN            NaN        NaN       NaN   \n",
       "3851           NaN              NaN            NaN        NaN       NaN   \n",
       "\n",
       "      Punitive  Aggravated  Future Care  \\\n",
       "0          NaN         NaN          NaN   \n",
       "1          NaN         NaN          NaN   \n",
       "2          NaN         NaN          NaN   \n",
       "3     100000.0         NaN          NaN   \n",
       "4     800000.0         NaN          NaN   \n",
       "...        ...         ...          ...   \n",
       "3847       NaN         NaN          NaN   \n",
       "3848       NaN         NaN          NaN   \n",
       "3849       NaN         NaN          NaN   \n",
       "3850       NaN         NaN          NaN   \n",
       "3851       NaN         NaN          NaN   \n",
       "\n",
       "                                        Judge Name Decision Length  \\\n",
       "0                                 S.F. Kelleher J.             115   \n",
       "1                                   H.J. Holmes J.             350   \n",
       "2                                 D.A. Halfyard J.              97   \n",
       "3                                   H. MacNaughton             525   \n",
       "4                                  E.A. Bennett J.             311   \n",
       "...                                            ...             ...   \n",
       "3847  Heard: August 29 (written submissions of the              10   \n",
       "3848                                  F.W. Cole J.              40   \n",
       "3849                              J.W. Williams J.             110   \n",
       "3850             Master R. McDiarmid (In Chambers)              27   \n",
       "3851                                 N.H. Smith J.              38   \n",
       "\n",
       "     Multiple defendants? Plaintiff Wins? Contributory Negligence Raised  \\\n",
       "0                       Y               Y                              Y   \n",
       "1                       N               Y                              N   \n",
       "2                       Y               Y                              Y   \n",
       "3                       Y               Y                              Y   \n",
       "4                       Y               Y                              N   \n",
       "...                   ...             ...                            ...   \n",
       "3847                    Y               Y                              N   \n",
       "3848                    Y               N                              N   \n",
       "3849                    N               N                              N   \n",
       "3850                    Y        OpenCase                              N   \n",
       "3851                    Y        OpenCase                              N   \n",
       "\n",
       "     Written Decision?   Registry  \n",
       "0                    Y  Vancouver  \n",
       "1                    Y  Vancouver  \n",
       "2                    Y    Nanaimo  \n",
       "3                    Y  Vancouver  \n",
       "4                    Y  Vancouver  \n",
       "...                ...        ...  \n",
       "3847                 Y  Vancouver  \n",
       "3848                 Y  Vancouver  \n",
       "3849                 Y  Vancouver  \n",
       "3850                 Y  Vancouver  \n",
       "3851                 Y  Vancouver  \n",
       "\n",
       "[3852 rows x 18 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['bow'] = dict(Counter(['this', 'is', 'a', 'a', 'test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bow': {'this': 1, 'is': 1, 'a': 2, 'test': 1}}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bow': {'this': 1, 'is': 1, 'a': 2, 'test': 1},\n",
       " 'this': 1,\n",
       " 'is': 1,\n",
       " 'a': 2,\n",
       " 'test': 1}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.update(Counter(['this', 'is', 'a', 'a', 'test']))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "d['this'] = 1\n",
    "\n",
    "d={k+'@BEFORE': v for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dict()\n",
    "p['this'] = 1\n",
    "\n",
    "p={k+'@AFTER': v for k, v in p.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this@AFTER': 1}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this@BEFORE': 1}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this@AFTER': 1, 'this@BEFORE': 1}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
