{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction Functions\n",
    "#### Work in Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `.ipynb` file is to hold code that has been cleaned up & ready to share with the team. This will help us conform to using the same form when storing data, etc. \n",
    "\n",
    "It also contains useful code snippets that we feel other team members may find useful when they are working on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule-Based Information Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_parse_BCJ(doc):\n",
    "    '''Given an entire case, finds static information within the case (information that can be pattern matched)\n",
    "    Expects a B.C.J. case format (British Columbia Judgments)\n",
    "    \n",
    "    The following fields are currently implemented:\n",
    "    - Case Title\n",
    "    - Judge Name\n",
    "    - Registry\n",
    "    - Year\n",
    "    - Decision Length (in paragraphs)\n",
    "    \n",
    "    The following fields are still being implemented & tweaked:\n",
    "    - Multiple Defendants\n",
    "    \n",
    "    Arguments: doc (String): The case in text format following the form used in the DOCX to TXT notebook\n",
    "    Returns: case_dict (Dictionary): Dictionary with rule based parsable fields filled in\n",
    "    '''\n",
    "    lines = doc.split('\\n')\n",
    "    case_dict = dict() \n",
    "    \n",
    "    # Fields that can be found via pattern matching\n",
    "    decision_len = re.search(r'\\(([0-9]+) paras\\.?\\)', doc) # e.g.) (100 paras.)\n",
    "    registry = re.search(r'Registry: ?([A-Za-z ]+)', doc) # e.g.) Registry: Vancouver\n",
    "    if not registry:\n",
    "        registry = re.search(r'([A-Za-z ]+) Registry No.', doc) # Alt form e.g.) Vancouver Registory No. XXX\n",
    "        if not registry:\n",
    "            print('WARNING: Registry could not be found (This shouldn\\'t occur! Will cause error!)')\n",
    "    \n",
    "    # Fields that are always in the same place\n",
    "    judge_name = lines[4].strip()\n",
    "    case_title = lines[0].strip()\n",
    "    \n",
    "    # Extract year from case_title (in case we want to make visualizations, etc.)\n",
    "    year = re.search(r'20[0-2][0-9]', case_title) # Limit regex to be from 2000 to 2029\n",
    "    \n",
    "    case_dict['case_title'] = case_title\n",
    "    case_dict['year'] = year.group(0)\n",
    "    case_dict['registry'] = registry.group(1).strip()\n",
    "    case_dict['judge'] = judge_name\n",
    "    case_dict['decision_length'] = decision_len.group(1)\n",
    "    case_dict['multiple_defendants'] = rule_based_multiple_defendants_parse(doc)\n",
    "    \n",
    "    return case_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_multiple_defendants_parse(doc):\n",
    "    ''' Work in progress. Subject to minor changes to Regex patterns.\n",
    "    \n",
    "    TODO:\n",
    "        - Clarify solicitor/client cases with Lachlan\n",
    "        - Clarify cases that say \"IN MATTER OF ...\", currently returning 'UNK' for these\n",
    "    \n",
    "    -----\n",
    "    \n",
    "    Given a case. Uses regex/pattern-matching to determine whether we have multiple defendants.\n",
    "    For the most part the logic relies on whether the langauge used implies plurality or not.\n",
    "    \n",
    "    Arguments: doc (String): The case in text format following the form used in the DOCX to TXT notebook\n",
    "    Returns: response (String, 'Y', 'N', or 'UNK')\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Cases with (Re) in the title always have one person involved\n",
    "    # May drop these cases depending on advice from Lachlan.\n",
    "    if '(Re)' in doc.split('\\n')[0]:\n",
    "        return 'N'\n",
    "    \n",
    "    # Case 1)\n",
    "    # Traditional/most common. Of form \"Between A, B, C, Plaintiff(s), X, Y, Z Defendant(s)\"\n",
    "    # Can successfully cover ~98% of data\n",
    "    regex_between_plaintiff_claimant = re.search(r'(Between.*([P|p]laintiff[s]?|[C|c]laimant[s]?|[A|a]ppellant[s]?|[P|p]etitioner[s]?).*([D|d]efendant[s]?|[R|r]espondent[s]?).*\\n)', doc)\n",
    "    \n",
    "    # Match found\n",
    "    if regex_between_plaintiff_claimant:\n",
    "        text = regex_between_plaintiff_claimant.group(0).lower()\n",
    "        if 'defendants' in text or 'respondents' in text:\n",
    "            return 'Y'\n",
    "        elif 'defendant' in text or 'respondent' in text:\n",
    "            return 'N'\n",
    "    \n",
    "    # If not found, try other less common cases\n",
    "    else:\n",
    "        # Case 2)\n",
    "        # Sometimes it does not mention the name of the second item. (Defendent/Respondent)\n",
    "        # We can estimate if there are multiple based on the number of \",\" in the line (Covers all cases in initial data)\n",
    "        regex_missing_defendent = re.search(r'(Between.*([P|p]laintiff[s]?|[C|c]laimant[s]?|[A|a]ppellant[s]?|[P|p]etitioner[s]?).*\\n)', doc)\n",
    "        if regex_missing_defendent:\n",
    "            text = regex_missing_defendent.group(0).lower()\n",
    "            if len(text.split(',')) > 5:\n",
    "                return 'Y'\n",
    "            else:\n",
    "                return 'N'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Case 3A) solicitor-client\n",
    "            # Some cases have a solicitor (lawyer) and a client\n",
    "            # Currently assuming the second item is the defendant\n",
    "            regex_solicitor_client = re.search(r'(Between.*([S|s]olicitor[s]?).*([C|c]lient[s]?))', doc)\n",
    "            if regex_solicitor_client:\n",
    "                text = regex_solicitor_client.group(0).lower()\n",
    "                if 'clients' in text:\n",
    "                    return 'Y'\n",
    "                else:\n",
    "                    return 'N'\n",
    "            else:\n",
    "                # Case 3B) client - solicitor\n",
    "                regex_client_solicitor = re.search(r'(Between.*([C|c]lient[s]?).*([S|s]olicitor[s]?))', doc)\n",
    "                if solicitor_client:\n",
    "                    text = regex_client_solicitor.group(0).lower()\n",
    "                    if 'solicitors' in text:\n",
    "                        return 'Y'\n",
    "                    else:\n",
    "                        return 'N'\n",
    "                else:\n",
    "                    return 'UNK'\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of using above functions\n",
    "\n",
    "Just putting parsed data from `P1.txt` into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case_title': 'Madill v. Sithivong, [2010] B.C.J. No. 2603',\n",
       " 'year': '2010',\n",
       " 'registry': 'Chilliwack',\n",
       " 'judge': 'N.E. Morrison J.',\n",
       " 'decision_length': '213',\n",
       " 'multiple_defendants': 'Y'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/Lexis Cases txt/P1.txt', 'r') as document:\n",
    "    document_data = document.read()\n",
    "        \n",
    "document_data = document_data.split('End of Document\\n') # Always split on 'End of Document\\n'\n",
    "case_parsed_data = []\n",
    "for case in document_data:\n",
    "    case = case.strip() # Make sure to strip!\n",
    "    \n",
    "    if len(case) == 0: # Skip empty lines\n",
    "        continue\n",
    "        \n",
    "    case_title = case.split('\\n')[0]\n",
    "    case_type = case.split('\\n')[1]\n",
    "    \n",
    "    if 'R. v.' in case_title: # Skip crown cases\n",
    "        continue\n",
    "    \n",
    "    if 'British Columbia Judgments' in case_type: # Make sure we're dealing with a B.C.J. case\n",
    "        case_parsed_data.append(rule_based_parse_BCJ(case))\n",
    "        \n",
    "case_parsed_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Statistics\n",
    "\n",
    "Code snippets that may be useful for gathering some statistics about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Necessary variables for code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../data/Lexis Cases txt/'\n",
    "file_prefix = 'P'\n",
    "file_suffix = '.txt'\n",
    "file_identifiers = range(1, 86) # Range from 1 to 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cases by type counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data/Lexis Cases txt/P1.txt\n",
      "Processing ../data/Lexis Cases txt/P2.txt\n",
      "Processing ../data/Lexis Cases txt/P3.txt\n",
      "Processing ../data/Lexis Cases txt/P4.txt\n",
      "Processing ../data/Lexis Cases txt/P5.txt\n",
      "Processing ../data/Lexis Cases txt/P6.txt\n",
      "Processing ../data/Lexis Cases txt/P7.txt\n",
      "Processing ../data/Lexis Cases txt/P8.txt\n",
      "Processing ../data/Lexis Cases txt/P9.txt\n",
      "Processing ../data/Lexis Cases txt/P10.txt\n",
      "Processing ../data/Lexis Cases txt/P11.txt\n",
      "Processing ../data/Lexis Cases txt/P12.txt\n",
      "Processing ../data/Lexis Cases txt/P13.txt\n",
      "Processing ../data/Lexis Cases txt/P14.txt\n",
      "Processing ../data/Lexis Cases txt/P15.txt\n",
      "Processing ../data/Lexis Cases txt/P16.txt\n",
      "Processing ../data/Lexis Cases txt/P17.txt\n",
      "Processing ../data/Lexis Cases txt/P18.txt\n",
      "Processing ../data/Lexis Cases txt/P19.txt\n",
      "Processing ../data/Lexis Cases txt/P20.txt\n",
      "Processing ../data/Lexis Cases txt/P21.txt\n",
      "Processing ../data/Lexis Cases txt/P22.txt\n",
      "Processing ../data/Lexis Cases txt/P23.txt\n",
      "Processing ../data/Lexis Cases txt/P24.txt\n",
      "Processing ../data/Lexis Cases txt/P25.txt\n",
      "Processing ../data/Lexis Cases txt/P26.txt\n",
      "Processing ../data/Lexis Cases txt/P27.txt\n",
      "Processing ../data/Lexis Cases txt/P28.txt\n",
      "Processing ../data/Lexis Cases txt/P29.txt\n",
      "Processing ../data/Lexis Cases txt/P30.txt\n",
      "Processing ../data/Lexis Cases txt/P31.txt\n",
      "Processing ../data/Lexis Cases txt/P32.txt\n",
      "Processing ../data/Lexis Cases txt/P33.txt\n",
      "Processing ../data/Lexis Cases txt/P34.txt\n",
      "Processing ../data/Lexis Cases txt/P35.txt\n",
      "Processing ../data/Lexis Cases txt/P36.txt\n",
      "Processing ../data/Lexis Cases txt/P37.txt\n",
      "Processing ../data/Lexis Cases txt/P38.txt\n",
      "Processing ../data/Lexis Cases txt/P39.txt\n",
      "Processing ../data/Lexis Cases txt/P40.txt\n",
      "Processing ../data/Lexis Cases txt/P41.txt\n",
      "Processing ../data/Lexis Cases txt/P42.txt\n",
      "Processing ../data/Lexis Cases txt/P43.txt\n",
      "Processing ../data/Lexis Cases txt/P44.txt\n",
      "Processing ../data/Lexis Cases txt/P45.txt\n",
      "Processing ../data/Lexis Cases txt/P46.txt\n",
      "Processing ../data/Lexis Cases txt/P47.txt\n",
      "Processing ../data/Lexis Cases txt/P48.txt\n",
      "Processing ../data/Lexis Cases txt/P49.txt\n",
      "Processing ../data/Lexis Cases txt/P50.txt\n",
      "Processing ../data/Lexis Cases txt/P51.txt\n",
      "Processing ../data/Lexis Cases txt/P52.txt\n",
      "Processing ../data/Lexis Cases txt/P53.txt\n",
      "Processing ../data/Lexis Cases txt/P54.txt\n",
      "Processing ../data/Lexis Cases txt/P55.txt\n",
      "Processing ../data/Lexis Cases txt/P56.txt\n",
      "Processing ../data/Lexis Cases txt/P57.txt\n",
      "Processing ../data/Lexis Cases txt/P58.txt\n",
      "Processing ../data/Lexis Cases txt/P59.txt\n",
      "Processing ../data/Lexis Cases txt/P60.txt\n",
      "Processing ../data/Lexis Cases txt/P61.txt\n",
      "Processing ../data/Lexis Cases txt/P62.txt\n",
      "Processing ../data/Lexis Cases txt/P63.txt\n",
      "Processing ../data/Lexis Cases txt/P64.txt\n",
      "Processing ../data/Lexis Cases txt/P65.txt\n",
      "Processing ../data/Lexis Cases txt/P66.txt\n",
      "Processing ../data/Lexis Cases txt/P67.txt\n",
      "Processing ../data/Lexis Cases txt/P68.txt\n",
      "Processing ../data/Lexis Cases txt/P69.txt\n",
      "Processing ../data/Lexis Cases txt/P70.txt\n",
      "Processing ../data/Lexis Cases txt/P71.txt\n",
      "Processing ../data/Lexis Cases txt/P72.txt\n",
      "Processing ../data/Lexis Cases txt/P73.txt\n",
      "Processing ../data/Lexis Cases txt/P74.txt\n",
      "Processing ../data/Lexis Cases txt/P75.txt\n",
      "Processing ../data/Lexis Cases txt/P76.txt\n",
      "Processing ../data/Lexis Cases txt/P77.txt\n",
      "Processing ../data/Lexis Cases txt/P78.txt\n",
      "Processing ../data/Lexis Cases txt/P79.txt\n",
      "Processing ../data/Lexis Cases txt/P80.txt\n",
      "Processing ../data/Lexis Cases txt/P81.txt\n",
      "Processing ../data/Lexis Cases txt/P82.txt\n",
      "Processing ../data/Lexis Cases txt/P83.txt\n",
      "Processing ../data/Lexis Cases txt/P84.txt\n",
      "Processing ../data/Lexis Cases txt/P85.txt\n"
     ]
    }
   ],
   "source": [
    "case_type_counts = defaultdict(int)\n",
    "\n",
    "for file_number in file_identifiers:\n",
    "\n",
    "    print('Processing ' + path_to_data + file_prefix + str(file_number) + file_suffix)\n",
    "\n",
    "    with open(path_to_data + file_prefix + str(file_number) + file_suffix, 'r') as document:\n",
    "        document_data = document.read()\n",
    "        \n",
    "    document_data = document_data.split('End of Document\\n') # Must have \\n as the phrase appears in one of the cases\n",
    "    for case in document_data:\n",
    "        case = case.strip()\n",
    "        # Just in-case we have an empty case in the list\n",
    "        if len(case) > 0:\n",
    "            case_title = case.split('\\n')[0]\n",
    "            case_type = case.split('\\n')[1]\n",
    "            if 'R. v.' in case_title:\n",
    "                case_type_counts['Crown Cases (R. v. ___)'] += 1\n",
    "            elif 'Canadian Health Facilities Law Guide' in case_type: # CHFL\n",
    "                case_type_counts['CHFL'] += 1\n",
    "            elif 'British Columbia Judgments' in case_type: # B.C.J.\n",
    "                case_type_counts['BCJ'] += 1\n",
    "            elif 'Canadian Insurance Law Reporter Cases' in case_type: # I.L.R.\n",
    "                case_type_counts['ILR'] += 1\n",
    "            elif 'Canadian Commercial Law Guide' in case_type: # CCLG\n",
    "                case_type_counts['CCLG'] += 1\n",
    "            elif 'Ontario Corporations Law Guide' in case_type: # OCLG\n",
    "                case_type_counts['OCLG'] += 1\n",
    "            elif 'Canadian Corporate Secretary\\'s Guide' in case_type: # CCSG\n",
    "                case_type_counts['CCSG'] += 1\n",
    "            elif 'Canadian Employment Benefits & Pension Guide' in case_type: # CBPG\n",
    "                case_type_counts['CBPG'] += 1\n",
    "            elif 'Alberta Corporations Law Guide' in case_type: # ACLG\n",
    "                case_type_counts['ACLG'] += 1\n",
    "            elif 'British Columbia Real Estate Law Guide' in case_type: # BREG\n",
    "                case_type_counts['BREG'] += 1\n",
    "            elif 'Canadian Native Law Reporter' in case_type: # C.N.L.R\n",
    "                case_type_counts['CNLR'] += 1\n",
    "            elif 'Dominion Tax Cases' in case_type: # DTC\n",
    "                case_type_counts['DTC'] += 1\n",
    "            elif 'Canadian Labour Law Reporter' in case_type: # CLLC\n",
    "                case_type_counts['CLLC'] += 1\n",
    "            elif 'British Columbia Corporations Law Guide' in case_type: # BCLG\n",
    "                case_type_counts['BCLG'] += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
