{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .DOCX to .TXT file converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### docx package may need to be installed\n",
    "#### To install enter command \"pip install docx\"\n",
    "#### [Documentation can be found here](https://python-docx.readthedocs.io/en/latest/index.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install docx\n",
    "import docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables to aid with filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../data/Lexis Cases/'\n",
    "file_prefix = 'P'\n",
    "file_suffix = '.DOCX'\n",
    "file_identifiers = range(1, 86) # Range from 1 to 85\n",
    "\n",
    "out_path = '../data/Lexis Cases txt/'\n",
    "out_file_suffix = '.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Extraction\n",
    "\n",
    "The library `docx` doesn't have simple support for going over each element in the document sequentially. I found a solution online that finds the children of each document and constructs new `Paragraph` and `Table` elements for the user. Code and link to the source can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is sourced from: https://github.com/python-openxml/python-docx/issues/40#issuecomment-90710401\n",
    "# with modification made from comment: \n",
    "\n",
    "# Currently, there is no built-in method of iterating over all items sequentially\n",
    "# We must manually iterate over children and call the constructors of Paragraph, Table\n",
    "# Code below summary:\n",
    "#      1. Grab body of document\n",
    "#      2. Check if the child in \"document.element.body.iterchildren()\" is CT_P, or CT_Tbl\n",
    "#      3. Call the Paragraph or Table constructor with the child and its parent (the document)\n",
    "#      4. Yield the paragraph/table for user to manipulate\n",
    "\n",
    "from docx.document import Document\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.table import _Cell, Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "\n",
    "\n",
    "def iter_block_items(parent):\n",
    "    \"\"\"\n",
    "    Yield each paragraph and table child within *parent*, in document order.\n",
    "    Each returned value is an instance of either Table or Paragraph. *parent*\n",
    "    would most commonly be a reference to a main Document object, but\n",
    "    also works for a _Cell object, which itself can contain paragraphs and tables.\n",
    "    \"\"\"\n",
    "    if isinstance(parent, Document):\n",
    "        parent_elm = parent.element.body\n",
    "    elif isinstance(parent, _Cell):\n",
    "        parent_elm = parent._tc\n",
    "    else:\n",
    "        raise ValueError(\"something's not right\")\n",
    "\n",
    "    for child in parent_elm.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            yield Paragraph(child, parent)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            yield Table(child, parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below streamlines opening each `.DOCX` file, reading the information, and writing it out to a `.txt` format. For tables our strategy is to concatenate each column for every row and treat it as a single sentence.\n",
    "\n",
    "To get the case title we need to access the documents `header` via the documents `sections` and pull out text from row 1, cell 0. I believe the \"page X of y\" is store in row 0, cell 0 but this information isn't needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data/Lexis Cases/P1.DOCX\n",
      "Processing ../data/Lexis Cases/P2.DOCX\n",
      "Processing ../data/Lexis Cases/P3.DOCX\n",
      "Processing ../data/Lexis Cases/P4.DOCX\n",
      "Processing ../data/Lexis Cases/P5.DOCX\n",
      "Processing ../data/Lexis Cases/P6.DOCX\n",
      "Processing ../data/Lexis Cases/P7.DOCX\n",
      "Processing ../data/Lexis Cases/P8.DOCX\n",
      "Processing ../data/Lexis Cases/P9.DOCX\n",
      "Processing ../data/Lexis Cases/P10.DOCX\n",
      "Processing ../data/Lexis Cases/P11.DOCX\n",
      "Processing ../data/Lexis Cases/P12.DOCX\n",
      "Processing ../data/Lexis Cases/P13.DOCX\n",
      "Processing ../data/Lexis Cases/P14.DOCX\n",
      "Processing ../data/Lexis Cases/P15.DOCX\n",
      "Processing ../data/Lexis Cases/P16.DOCX\n",
      "Processing ../data/Lexis Cases/P17.DOCX\n",
      "Processing ../data/Lexis Cases/P18.DOCX\n",
      "Processing ../data/Lexis Cases/P19.DOCX\n",
      "Processing ../data/Lexis Cases/P20.DOCX\n",
      "Processing ../data/Lexis Cases/P21.DOCX\n",
      "Processing ../data/Lexis Cases/P22.DOCX\n",
      "Processing ../data/Lexis Cases/P23.DOCX\n",
      "Processing ../data/Lexis Cases/P24.DOCX\n",
      "Processing ../data/Lexis Cases/P25.DOCX\n",
      "Processing ../data/Lexis Cases/P26.DOCX\n",
      "Processing ../data/Lexis Cases/P27.DOCX\n",
      "Processing ../data/Lexis Cases/P28.DOCX\n",
      "Processing ../data/Lexis Cases/P29.DOCX\n",
      "Processing ../data/Lexis Cases/P30.DOCX\n",
      "Processing ../data/Lexis Cases/P31.DOCX\n",
      "Processing ../data/Lexis Cases/P32.DOCX\n",
      "Processing ../data/Lexis Cases/P33.DOCX\n",
      "Processing ../data/Lexis Cases/P34.DOCX\n",
      "Processing ../data/Lexis Cases/P35.DOCX\n",
      "Processing ../data/Lexis Cases/P36.DOCX\n",
      "Processing ../data/Lexis Cases/P37.DOCX\n",
      "Processing ../data/Lexis Cases/P38.DOCX\n",
      "Processing ../data/Lexis Cases/P39.DOCX\n",
      "Processing ../data/Lexis Cases/P40.DOCX\n",
      "Processing ../data/Lexis Cases/P41.DOCX\n",
      "Processing ../data/Lexis Cases/P42.DOCX\n",
      "Processing ../data/Lexis Cases/P43.DOCX\n",
      "Processing ../data/Lexis Cases/P44.DOCX\n",
      "Processing ../data/Lexis Cases/P45.DOCX\n",
      "Processing ../data/Lexis Cases/P46.DOCX\n",
      "Processing ../data/Lexis Cases/P47.DOCX\n",
      "Processing ../data/Lexis Cases/P48.DOCX\n",
      "Processing ../data/Lexis Cases/P49.DOCX\n",
      "Processing ../data/Lexis Cases/P50.DOCX\n",
      "Processing ../data/Lexis Cases/P51.DOCX\n",
      "Processing ../data/Lexis Cases/P52.DOCX\n",
      "Processing ../data/Lexis Cases/P53.DOCX\n",
      "Processing ../data/Lexis Cases/P54.DOCX\n",
      "Processing ../data/Lexis Cases/P55.DOCX\n",
      "Processing ../data/Lexis Cases/P56.DOCX\n",
      "Processing ../data/Lexis Cases/P57.DOCX\n",
      "Processing ../data/Lexis Cases/P58.DOCX\n",
      "Processing ../data/Lexis Cases/P59.DOCX\n",
      "Processing ../data/Lexis Cases/P60.DOCX\n",
      "Processing ../data/Lexis Cases/P61.DOCX\n",
      "Processing ../data/Lexis Cases/P62.DOCX\n",
      "Processing ../data/Lexis Cases/P63.DOCX\n",
      "Processing ../data/Lexis Cases/P64.DOCX\n",
      "Processing ../data/Lexis Cases/P65.DOCX\n",
      "Processing ../data/Lexis Cases/P66.DOCX\n",
      "Processing ../data/Lexis Cases/P67.DOCX\n",
      "Processing ../data/Lexis Cases/P68.DOCX\n",
      "Processing ../data/Lexis Cases/P69.DOCX\n",
      "Processing ../data/Lexis Cases/P70.DOCX\n",
      "Processing ../data/Lexis Cases/P71.DOCX\n",
      "Processing ../data/Lexis Cases/P72.DOCX\n",
      "Processing ../data/Lexis Cases/P73.DOCX\n",
      "Processing ../data/Lexis Cases/P74.DOCX\n",
      "Processing ../data/Lexis Cases/P75.DOCX\n",
      "Processing ../data/Lexis Cases/P76.DOCX\n",
      "Processing ../data/Lexis Cases/P77.DOCX\n"
     ]
    }
   ],
   "source": [
    "for file_number in file_identifiers:\n",
    "    print('Processing ' + path_to_data + file_prefix + str(file_number) + file_suffix)\n",
    "    \n",
    "    # Open the document\n",
    "    # (Note: docx.Document is different from docx.document.Document)\n",
    "    document = docx.Document(path_to_data + file_prefix + str(file_number) + file_suffix)\n",
    "    file_text = ''\n",
    "\n",
    "    start_of_case = True\n",
    "    doc_section = 0\n",
    "    \n",
    "    # Iterate over each item in the body\n",
    "    for item in iter_block_items(document):\n",
    "\n",
    "        # If at start of case, store the header (case name)\n",
    "        # as the first entry. Must access 'document.sections[].header' to do so.\n",
    "        if start_of_case:\n",
    "            header = document.sections[doc_section].header\n",
    "            case_title = header.tables[0].cell(1, 0).text\n",
    "            file_text += case_title.strip() + '\\n'\n",
    "            doc_section += 2\n",
    "            start_of_case = False\n",
    "        \n",
    "        # If item is a PARAGRAPH\n",
    "        if isinstance(item, Paragraph):\n",
    "            # Skip over any empty lines\n",
    "            if len(item.text.strip()) > 0:\n",
    "                file_text += item.text.strip() + '\\n'\n",
    "\n",
    "            # Check if we are at the last line of a case\n",
    "            # to make sure we insert the header of the following case\n",
    "            if item.text.strip() == 'End of Document':\n",
    "                start_of_case = True \n",
    "          \n",
    "        # If item is a TABLE\n",
    "        elif isinstance(item, Table): \n",
    "            # We group everything across a row as one \"sentence\" in our .txt file\n",
    "            # Currently have no better ideas. This seems to be the most common format of tables in our .docx files\n",
    "            for row in item.rows:\n",
    "                text = [cell.text.strip() for cell in row.cells]\n",
    "                file_text += ' '.join(text) + '\\n'\n",
    "        \n",
    "            \n",
    "    # Save as .txt\n",
    "    with open(out_path + file_prefix + str(file_number) + out_file_suffix, 'w') as out_file:\n",
    "        out_file.write(file_text)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
